{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2XnfFFR1prk"
   },
   "source": [
    "## Data Acquisition and Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Jb2hqP0Hdm7"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def load_data(p_ohlc):\n",
    "    ohlc = p_ohlc\n",
    "    ohlc[\"previousClose\"] = ohlc[\"Close\"].shift(1)\n",
    "    ohlc[\"color\"] = np.where(ohlc[\"Close\"] > ohlc[\"previousClose\"], \"green\", \"red\")\n",
    "    ohlc[\"fill\"] = np.where(ohlc[\"Close\"] > ohlc[\"Open\"], \"rgba(255, 0, 0, 0)\", ohlc[\"color\"])\n",
    "    ohlc[\"Percentage\"] = ohlc[\"Volume\"] * 100 / ohlc[\"Volume\"].sum()\n",
    "    price_bins = ohlc.copy()\n",
    "    price_bins[\"Close\"] = price_bins[\"Close\"].round()\n",
    "    price_bins = price_bins.groupby(\"Close\", as_index=False)[\"Volume\"].sum()\n",
    "    price_bins[\"Percentage\"] = price_bins[\"Volume\"] * 100 / price_bins[\"Volume\"].sum()\n",
    "    return ohlc, price_bins\n",
    "\n",
    "def hollow_candlesticks(data, p_name):\n",
    "    fig = make_subplots(\n",
    "        rows=2,\n",
    "        cols=2,\n",
    "        shared_xaxes=\"columns\",\n",
    "        shared_yaxes=\"rows\",\n",
    "        column_width=[0.8, 0.2],\n",
    "        row_heights=[0.8, 0.2],\n",
    "        horizontal_spacing=0,\n",
    "        vertical_spacing=0,\n",
    "        subplot_titles=[\"Candlestick\", \"Price Bins\", \"Volume\", \"\"]\n",
    "    )\n",
    "    showlegend = True\n",
    "    for index, row in data[0].iterrows():\n",
    "        color = dict(fillcolor=row[\"fill\"], line=dict(color=row[\"color\"]))\n",
    "        fig.add_trace(\n",
    "            go.Candlestick(\n",
    "                x=[index],\n",
    "                open=[row[\"Open\"]],\n",
    "                high=[row[\"High\"]],\n",
    "                low=[row[\"Low\"]],\n",
    "                close=[row[\"Close\"]],\n",
    "                increasing=color,\n",
    "                decreasing=color,\n",
    "                showlegend=showlegend,\n",
    "                name=p_name,\n",
    "                legendgroup=\"Hollow Candlesticks\"\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1\n",
    "        )\n",
    "        showlegend = False\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=data[0].index,\n",
    "            y=data[0][\"Volume\"],\n",
    "            text=data[0][\"Percentage\"],\n",
    "            marker_line_color=data[0][\"color\"],\n",
    "            marker_color=data[0][\"fill\"],\n",
    "            name=\"Volume\",\n",
    "            texttemplate=\"%{text:.2f}%\",\n",
    "            hoverinfo=\"x+y\",\n",
    "            textfont=dict(color=\"white\")\n",
    "        ),\n",
    "        col=1,\n",
    "        row=2,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            y=data[1][\"Close\"],\n",
    "            x=data[1][\"Volume\"],\n",
    "            text=data[1][\"Percentage\"],\n",
    "            name=\"Price Bins\",\n",
    "            orientation=\"h\",\n",
    "            marker_color=\"yellow\",\n",
    "            texttemplate=\"%{text:.2f}% @ %{y}\",\n",
    "            hoverinfo=\"x+y\"\n",
    "        ),\n",
    "        col=2,\n",
    "        row=1,\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        rangebreaks=[dict(bounds=[\"sat\", \"mon\"])],\n",
    "        rangeslider_visible=False,\n",
    "        col=1\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        showticklabels=True,\n",
    "        showspikes=True,\n",
    "        showgrid=True,\n",
    "        col=2,\n",
    "        row=1\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        template=\"plotly_dark\",\n",
    "        hovermode=\"x unified\",\n",
    "        title_text=f\"Hollow Candlesticks for {p_name}\"\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# Symbols list\n",
    "symbols = ['AEFES.IS', 'AGHOL.IS', 'AKBNK.IS', 'AKFGY.IS', 'AKSA.IS', 'AKSEN.IS',\n",
    "           'ALARK.IS', 'ALBRK.IS', 'ALGYO.IS', 'ALKIM.IS', 'ARCLK.IS', 'BAGFS.IS',\n",
    "           'BERA.IS', 'BIMAS.IS', 'BRYAT.IS', 'BUCIM.IS', 'CCOLA.IS', 'CEMTS.IS',\n",
    "           'CIMSA.IS', 'DEVA.IS', 'DOAS.IS', 'DOHOL.IS', 'ECILC.IS', 'EGEEN.IS',\n",
    "           'EKGYO.IS', 'ENJSA.IS', 'ENKAI.IS', 'ERBOS.IS', 'EREGL.IS', 'FROTO.IS',\n",
    "           'GARAN.IS',  'GESAN.IS', 'GLYHO.IS', 'GOZDE.IS', 'GSDHO.IS', 'GUBRF.IS',\n",
    "           'GWIND.IS', 'HALKB.IS', 'ISCTR.IS', 'ISDMR.IS', 'ISFIN.IS', 'ISGYO.IS',\n",
    "           'ISMEN.IS', 'JANTS.IS', 'KARSN.IS', 'KARTN.IS', 'KCHOL.IS', 'KONTR.IS',\n",
    "           'KORDS.IS', 'KOZAA.IS', 'KOZAL.IS', 'KRDMD.IS', 'LOGO.IS', 'MAVI.IS',\n",
    "           'MGROS.IS', 'NTHOL.IS', 'NUGYO.IS', 'ODAS.IS', 'OTKAR.IS', 'OYAKC.IS',\n",
    "           'PETKM.IS', 'PGSUS.IS', 'PRKAB.IS',  'QUAGR.IS', 'SAHOL.IS', 'SASA.IS',\n",
    "           'SKBNK.IS', 'SMRTG.IS', 'SNGYO.IS', 'SOKM.IS', 'TAVHL.IS', 'TCELL.IS',\n",
    "           'THYAO.IS', 'TKFEN.IS', 'TMSN.IS', 'TOASO.IS', 'TRGYO.IS', 'TSKB.IS',\n",
    "           'TSPOR.IS', 'TTKOM.IS', 'TTRAK.IS', 'TUKAS.IS', 'TUPRS.IS', 'TURSG.IS',\n",
    "           'ULKER.IS', 'VAKBN.IS', 'VESBE.IS', 'VESTL.IS', 'YATAS.IS', 'YKBNK.IS', 'YYLGD.IS']\n",
    "\n",
    "# Pull the data for each symbol and call the hollow_candlesticks function\n",
    "for symbol in symbols:\n",
    "     # Download data with a potentially longer period (adjust as needed)\n",
    "    data = yf.download(symbol, start=\"2023-10-01\", end=\"2023-10-31\", interval=\"1h\")\n",
    "    ohlc, price_bins = load_data(data)\n",
    "\n",
    "    # Cleaning process: Drop NaN values\n",
    "    ohlc = ohlc.dropna()\n",
    "    price_bins = price_bins.dropna()\n",
    "\n",
    "    hollow_candlesticks((ohlc, price_bins), symbol)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3KtGgUj1syx"
   },
   "source": [
    "## Feature Engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDqp3MtxoGSr"
   },
   "outputs": [],
   "source": [
    "!pip install catboost\n",
    "\n",
    "url = 'https://anaconda.org/conda-forge/libta-lib/0.4.0/download/linux-64/libta-lib-0.4.0-h166bdaf_1.tar.bz2'\n",
    "!curl -L $url | tar xj -C /usr/lib/x86_64-linux-gnu/ lib --strip-components=1\n",
    "url = 'https://anaconda.org/conda-forge/ta-lib/0.4.19/download/linux-64/ta-lib-0.4.19-py310hde88566_4.tar.bz2'\n",
    "!curl -L $url | tar xj -C /usr/local/lib/python3.10/dist-packages/ lib/python3.10/site-packages/talib --strip-components=3\n",
    "import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L51lTK0X-u-c",
    "outputId": "8e0fcd7c-6577-4345-d188-c99c28701080"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-74-8dfdf35155f2>:49: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import talib\n",
    "\n",
    "# Function to extract features using talib\n",
    "def extract_features(data):\n",
    "    features = pd.DataFrame()\n",
    "\n",
    "    # Basic candlestick features\n",
    "    features['wick_length'] = data['High'] - data[['Open', 'Close']].max(axis=1)\n",
    "    features['shadow_ratio'] = features['wick_length'] / (data['Close'] - data['Open'])\n",
    "\n",
    "    # Technical indicators using talib\n",
    "    features['EMA_5'] = talib.EMA(data['Close'], timeperiod=5)\n",
    "    features['EMA_13'] = talib.EMA(data['Close'], timeperiod=13)\n",
    "    features['EMA_50'] = talib.EMA(data['Close'], timeperiod=50)\n",
    "\n",
    "    features['SMA_5'] = talib.EMA(data['Close'], timeperiod=5)\n",
    "    features['SMA_13'] = talib.EMA(data['Close'], timeperiod=13)\n",
    "    features['SMA_50'] = talib.EMA(data['Close'], timeperiod=50)\n",
    "\n",
    "    features['MFI'] = talib.MFI(data['High'], data['Low'], data['Close'], data['Volume'], timeperiod=14)\n",
    "    features['MACD'], _, _ = talib.MACD(data['Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    features['Volume'] = data['Volume']\n",
    "    features['RSI'] = talib.RSI(data['Close'], timeperiod=14)\n",
    "\n",
    "    # Target variable - Binary classification based on mean value\n",
    "    close_mean = data['Close'].mean()\n",
    "    features['NextCandlestickPattern'] = np.where(data['Close'].fillna(close_mean) > close_mean, 1, 0)\n",
    "\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "# Create an empty DataFrame to store features\n",
    "features_df = pd.DataFrame()\n",
    "\n",
    "# Loop through symbols and extract features\n",
    "for symbol in symbols:\n",
    "\n",
    "\n",
    "    # Check if there is any data before applying the imputer\n",
    "    if not data.empty:\n",
    "        # Handle missing values using SimpleImputer\n",
    "        data['Close'] = SimpleImputer(strategy='median').fit_transform(data[['Close']])\n",
    "\n",
    "        extracted_features = extract_features(data)\n",
    "        extracted_features['Symbol'] = symbol\n",
    "        features_df = features_df.append(extracted_features, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKMVRAdg_dAI"
   },
   "source": [
    "## Machine Learning Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9j_3FbewBcmD"
   },
   "outputs": [],
   "source": [
    "!pip install optuna\n",
    "!pip install git+https://github.com/optuna/optuna.git\n",
    "!conda install -c conda-forge optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KnHpSrtg3cz0",
    "outputId": "cae279bb-49f9-4191-97c4-4846628308b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-f01c740bf7f1>:70: FutureWarning:\n",
      "\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\n",
      "[I 2023-12-24 13:58:55,054] A new study created in memory with name: no-name-a628bcee-d5ab-4aa2-b7e4-1a830c723a90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-24 13:58:55,861] Trial 0 finished with value: 0.0 and parameters: {'n_estimators': 131, 'max_depth': 30, 'min_samples_split': 0.4250025823585637, 'min_samples_leaf': 0.13403941381819662}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:58:56,469] Trial 1 finished with value: 0.0 and parameters: {'n_estimators': 107, 'max_depth': 26, 'min_samples_split': 0.2796201077845303, 'min_samples_leaf': 0.26092609461551264}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:58:57,162] Trial 2 finished with value: 0.0 and parameters: {'n_estimators': 235, 'max_depth': 19, 'min_samples_split': 0.7232370738103888, 'min_samples_leaf': 0.4001756379694913}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:58:59,491] Trial 3 finished with value: 0.0 and parameters: {'n_estimators': 419, 'max_depth': 26, 'min_samples_split': 0.495866415240223, 'min_samples_leaf': 0.18642241342038385}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:00,064] Trial 4 finished with value: 0.0 and parameters: {'n_estimators': 125, 'max_depth': 15, 'min_samples_split': 0.7234971469124314, 'min_samples_leaf': 0.1363178911234366}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:01,850] Trial 5 finished with value: 0.0 and parameters: {'n_estimators': 403, 'max_depth': 25, 'min_samples_split': 0.5438225799161008, 'min_samples_leaf': 0.3643024816634469}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:03,973] Trial 6 finished with value: 0.0 and parameters: {'n_estimators': 316, 'max_depth': 16, 'min_samples_split': 0.1471119796943928, 'min_samples_leaf': 0.2181442135972881}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:05,271] Trial 7 finished with value: 0.0 and parameters: {'n_estimators': 240, 'max_depth': 17, 'min_samples_split': 0.27147534338930457, 'min_samples_leaf': 0.28226076040087555}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:06,725] Trial 8 finished with value: 0.0 and parameters: {'n_estimators': 494, 'max_depth': 8, 'min_samples_split': 0.18193839544378115, 'min_samples_leaf': 0.3791682817862311}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:07,210] Trial 9 finished with value: 0.0 and parameters: {'n_estimators': 161, 'max_depth': 27, 'min_samples_split': 0.28729759253074605, 'min_samples_leaf': 0.4892514075931764}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:07,496] Trial 10 finished with value: 0.0 and parameters: {'n_estimators': 80, 'max_depth': 5, 'min_samples_split': 0.9466597871673708, 'min_samples_leaf': 0.10469604962357017}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:07,827] Trial 11 finished with value: 0.0 and parameters: {'n_estimators': 54, 'max_depth': 30, 'min_samples_split': 0.4050248994083661, 'min_samples_leaf': 0.25906492931896113}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:09,083] Trial 12 finished with value: 0.0 and parameters: {'n_estimators': 185, 'max_depth': 22, 'min_samples_split': 0.3811127456739859, 'min_samples_leaf': 0.1652070949056721}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:09,456] Trial 13 finished with value: 0.0 and parameters: {'n_estimators': 116, 'max_depth': 30, 'min_samples_split': 0.6895705287562027, 'min_samples_leaf': 0.22996786092012245}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:10,555] Trial 14 finished with value: 0.0 and parameters: {'n_estimators': 196, 'max_depth': 22, 'min_samples_split': 0.415092913838488, 'min_samples_leaf': 0.3123061674981662}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:11,510] Trial 15 finished with value: 0.0 and parameters: {'n_estimators': 312, 'max_depth': 12, 'min_samples_split': 0.2972291346352886, 'min_samples_leaf': 0.3212111300387069}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:11,941] Trial 16 finished with value: 0.0 and parameters: {'n_estimators': 128, 'max_depth': 23, 'min_samples_split': 0.6067965628020201, 'min_samples_leaf': 0.4437117296934683}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:12,542] Trial 17 finished with value: 0.0 and parameters: {'n_estimators': 85, 'max_depth': 28, 'min_samples_split': 0.1116917770418196, 'min_samples_leaf': 0.18131401552230436}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:13,549] Trial 18 finished with value: 0.0 and parameters: {'n_estimators': 267, 'max_depth': 24, 'min_samples_split': 0.861693224622496, 'min_samples_leaf': 0.10776299893550796}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:14,854] Trial 19 finished with value: 0.0 and parameters: {'n_estimators': 154, 'max_depth': 19, 'min_samples_split': 0.47178813151925675, 'min_samples_leaf': 0.22942466684484203}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:15,839] Trial 20 finished with value: 0.0 and parameters: {'n_estimators': 209, 'max_depth': 30, 'min_samples_split': 0.2304593089349628, 'min_samples_leaf': 0.3415098445439159}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:16,835] Trial 21 finished with value: 0.0 and parameters: {'n_estimators': 234, 'max_depth': 20, 'min_samples_split': 0.7359638204333544, 'min_samples_leaf': 0.40366255569512804}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:17,737] Trial 22 finished with value: 0.0 and parameters: {'n_estimators': 298, 'max_depth': 13, 'min_samples_split': 0.8097320720127474, 'min_samples_leaf': 0.4321069276444295}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:18,068] Trial 23 finished with value: 0.0 and parameters: {'n_estimators': 91, 'max_depth': 27, 'min_samples_split': 0.6173526546166486, 'min_samples_leaf': 0.4970674789961652}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:20,093] Trial 24 finished with value: 0.0 and parameters: {'n_estimators': 359, 'max_depth': 28, 'min_samples_split': 0.3517289949196005, 'min_samples_leaf': 0.27044330557688884}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:20,607] Trial 25 finished with value: 0.0 and parameters: {'n_estimators': 158, 'max_depth': 20, 'min_samples_split': 0.6112356406897305, 'min_samples_leaf': 0.4440158765551225}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:21,359] Trial 26 finished with value: 0.0 and parameters: {'n_estimators': 241, 'max_depth': 25, 'min_samples_split': 0.4522867974870754, 'min_samples_leaf': 0.3513801975483144}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:21,602] Trial 27 finished with value: 0.0 and parameters: {'n_estimators': 66, 'max_depth': 9, 'min_samples_split': 0.5509024062017251, 'min_samples_leaf': 0.39426068170746914}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:21,974] Trial 28 finished with value: 0.0 and parameters: {'n_estimators': 109, 'max_depth': 19, 'min_samples_split': 0.9804192214304832, 'min_samples_leaf': 0.13630445187956583}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:23,051] Trial 29 finished with value: 0.0 and parameters: {'n_estimators': 168, 'max_depth': 26, 'min_samples_split': 0.3381408780284768, 'min_samples_leaf': 0.19852509671446938}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:25,054] Trial 30 finished with value: 0.0 and parameters: {'n_estimators': 355, 'max_depth': 22, 'min_samples_split': 0.21118800096193502, 'min_samples_leaf': 0.2595481964453649}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:28,455] Trial 31 finished with value: 0.0 and parameters: {'n_estimators': 473, 'max_depth': 28, 'min_samples_split': 0.47811977512552184, 'min_samples_leaf': 0.14882849512599933}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:31,630] Trial 32 finished with value: 0.0 and parameters: {'n_estimators': 439, 'max_depth': 24, 'min_samples_split': 0.5367708795832747, 'min_samples_leaf': 0.1349082272810364}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:32,767] Trial 33 finished with value: 0.0 and parameters: {'n_estimators': 383, 'max_depth': 26, 'min_samples_split': 0.6902857028110022, 'min_samples_leaf': 0.20305310363204734}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:33,528] Trial 34 finished with value: 0.0 and parameters: {'n_estimators': 136, 'max_depth': 14, 'min_samples_split': 0.5201019757512435, 'min_samples_leaf': 0.29293193680702034}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:35,558] Trial 35 finished with value: 0.0 and parameters: {'n_estimators': 286, 'max_depth': 18, 'min_samples_split': 0.32503323702404074, 'min_samples_leaf': 0.16792285181156177}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:36,860] Trial 36 finished with value: 0.0 and parameters: {'n_estimators': 439, 'max_depth': 16, 'min_samples_split': 0.8382960586824569, 'min_samples_leaf': 0.2356162437349619}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:38,526] Trial 37 finished with value: 0.0 and parameters: {'n_estimators': 260, 'max_depth': 29, 'min_samples_split': 0.2669753021607817, 'min_samples_leaf': 0.19697296485045407}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:39,561] Trial 38 finished with value: 0.0 and parameters: {'n_estimators': 352, 'max_depth': 25, 'min_samples_split': 0.7374850316137552, 'min_samples_leaf': 0.1284334336577614}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:41,003] Trial 39 finished with value: 0.0 and parameters: {'n_estimators': 205, 'max_depth': 11, 'min_samples_split': 0.41579169401780625, 'min_samples_leaf': 0.24669196989323022}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:43,371] Trial 40 finished with value: 0.0 and parameters: {'n_estimators': 221, 'max_depth': 4, 'min_samples_split': 0.16506492054990363, 'min_samples_leaf': 0.16063677915440916}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:43,664] Trial 41 finished with value: 0.0 and parameters: {'n_estimators': 52, 'max_depth': 15, 'min_samples_split': 0.6722291183208768, 'min_samples_leaf': 0.11314683020954397}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:44,017] Trial 42 finished with value: 0.0 and parameters: {'n_estimators': 103, 'max_depth': 17, 'min_samples_split': 0.7783231513876014, 'min_samples_leaf': 0.17830504737717023}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:44,899] Trial 43 finished with value: 0.0 and parameters: {'n_estimators': 143, 'max_depth': 21, 'min_samples_split': 0.5784881804642482, 'min_samples_leaf': 0.12290344905092805}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:45,456] Trial 44 finished with value: 0.0 and parameters: {'n_estimators': 182, 'max_depth': 7, 'min_samples_split': 0.8806243211998379, 'min_samples_leaf': 0.2161312861620242}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:45,862] Trial 45 finished with value: 0.0 and parameters: {'n_estimators': 118, 'max_depth': 29, 'min_samples_split': 0.6413159371444148, 'min_samples_leaf': 0.10087966070829356}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:46,356] Trial 46 finished with value: 0.0 and parameters: {'n_estimators': 75, 'max_depth': 15, 'min_samples_split': 0.5151415166370316, 'min_samples_leaf': 0.15564646513651403}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:46,931] Trial 47 finished with value: 0.0 and parameters: {'n_estimators': 177, 'max_depth': 11, 'min_samples_split': 0.9005042345320804, 'min_samples_leaf': 0.2844826715381191}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:47,927] Trial 48 finished with value: 0.0 and parameters: {'n_estimators': 332, 'max_depth': 30, 'min_samples_split': 0.39404870034395445, 'min_samples_leaf': 0.32187975264579377}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:48,325] Trial 49 finished with value: 0.0 and parameters: {'n_estimators': 126, 'max_depth': 23, 'min_samples_split': 0.7306497005790339, 'min_samples_leaf': 0.4688119228509318}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:48,873] Trial 50 finished with value: 0.0 and parameters: {'n_estimators': 90, 'max_depth': 26, 'min_samples_split': 0.4381465908021945, 'min_samples_leaf': 0.17952174348606495}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:50,206] Trial 51 finished with value: 0.0 and parameters: {'n_estimators': 447, 'max_depth': 27, 'min_samples_split': 0.48380599815987557, 'min_samples_leaf': 0.3699465464109262}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:51,407] Trial 52 finished with value: 0.0 and parameters: {'n_estimators': 397, 'max_depth': 24, 'min_samples_split': 0.5640850641629652, 'min_samples_leaf': 0.40291953961763227}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:54,379] Trial 53 finished with value: 0.0 and parameters: {'n_estimators': 393, 'max_depth': 23, 'min_samples_split': 0.3663533003980543, 'min_samples_leaf': 0.14448545890073208}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:56,542] Trial 54 finished with value: 0.0 and parameters: {'n_estimators': 462, 'max_depth': 29, 'min_samples_split': 0.11493758240572355, 'min_samples_leaf': 0.3680584273433105}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:58,062] Trial 55 finished with value: 0.0 and parameters: {'n_estimators': 425, 'max_depth': 21, 'min_samples_split': 0.6509081242261423, 'min_samples_leaf': 0.41996888901459123}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:59,487] Trial 56 finished with value: 0.0 and parameters: {'n_estimators': 486, 'max_depth': 17, 'min_samples_split': 0.2974313529476734, 'min_samples_leaf': 0.3365151298703573}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 13:59:59,986] Trial 57 finished with value: 0.0 and parameters: {'n_estimators': 154, 'max_depth': 25, 'min_samples_split': 0.5016459342963036, 'min_samples_leaf': 0.38629099439531733}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:01,277] Trial 58 finished with value: 0.0 and parameters: {'n_estimators': 416, 'max_depth': 28, 'min_samples_split': 0.7686858121488933, 'min_samples_leaf': 0.3051364202876532}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:02,755] Trial 59 finished with value: 0.0 and parameters: {'n_estimators': 258, 'max_depth': 27, 'min_samples_split': 0.44093415222750304, 'min_samples_leaf': 0.2104654816726117}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:03,102] Trial 60 finished with value: 0.0 and parameters: {'n_estimators': 102, 'max_depth': 19, 'min_samples_split': 0.6024910836324752, 'min_samples_leaf': 0.35104625798214373}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:04,911] Trial 61 finished with value: 0.0 and parameters: {'n_estimators': 322, 'max_depth': 13, 'min_samples_split': 0.1646459526636478, 'min_samples_leaf': 0.22666504314648123}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:07,180] Trial 62 finished with value: 0.0 and parameters: {'n_estimators': 407, 'max_depth': 18, 'min_samples_split': 0.24959861105740921, 'min_samples_leaf': 0.2660765977071685}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:09,724] Trial 63 finished with value: 0.0 and parameters: {'n_estimators': 304, 'max_depth': 16, 'min_samples_split': 0.11343512790359608, 'min_samples_leaf': 0.24664923139147932}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:12,552] Trial 64 finished with value: 0.0 and parameters: {'n_estimators': 379, 'max_depth': 15, 'min_samples_split': 0.20076160637079954, 'min_samples_leaf': 0.1890155684361825}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:14,565] Trial 65 finished with value: 0.0 and parameters: {'n_estimators': 279, 'max_depth': 21, 'min_samples_split': 0.31044143381593126, 'min_samples_leaf': 0.17168796247602974}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:15,586] Trial 66 finished with value: 0.0 and parameters: {'n_estimators': 338, 'max_depth': 13, 'min_samples_split': 0.7069523146945689, 'min_samples_leaf': 0.4687021800542996}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:16,937] Trial 67 finished with value: 0.0 and parameters: {'n_estimators': 232, 'max_depth': 26, 'min_samples_split': 0.14725831889021182, 'min_samples_leaf': 0.22228638396553477}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:17,541] Trial 68 finished with value: 0.0 and parameters: {'n_estimators': 193, 'max_depth': 18, 'min_samples_split': 0.5390017773260574, 'min_samples_leaf': 0.42064679621021694}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:18,305] Trial 69 finished with value: 0.0 and parameters: {'n_estimators': 133, 'max_depth': 20, 'min_samples_split': 0.5901231515065737, 'min_samples_leaf': 0.24119928373181435}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:22,088] Trial 70 finished with value: 0.0 and parameters: {'n_estimators': 376, 'max_depth': 23, 'min_samples_split': 0.23089402156716426, 'min_samples_leaf': 0.11370540172198197}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:24,171] Trial 71 finished with value: 0.0 and parameters: {'n_estimators': 249, 'max_depth': 16, 'min_samples_split': 0.26701365181365844, 'min_samples_leaf': 0.2769598049650432}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:25,422] Trial 72 finished with value: 0.0 and parameters: {'n_estimators': 216, 'max_depth': 25, 'min_samples_split': 0.35562447812036746, 'min_samples_leaf': 0.25489576702319117}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:25,858] Trial 73 finished with value: 0.0 and parameters: {'n_estimators': 76, 'max_depth': 12, 'min_samples_split': 0.38616137263829187, 'min_samples_leaf': 0.3148792150106497}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:26,347] Trial 74 finished with value: 0.0 and parameters: {'n_estimators': 144, 'max_depth': 14, 'min_samples_split': 0.6406809866624796, 'min_samples_leaf': 0.14688504380802997}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:26,904] Trial 75 finished with value: 0.0 and parameters: {'n_estimators': 169, 'max_depth': 17, 'min_samples_split': 0.455799396184429, 'min_samples_leaf': 0.32906147202111447}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:27,303] Trial 76 finished with value: 0.0 and parameters: {'n_estimators': 62, 'max_depth': 22, 'min_samples_split': 0.418452414637851, 'min_samples_leaf': 0.29610902788395793}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:29,319] Trial 77 finished with value: 0.0 and parameters: {'n_estimators': 295, 'max_depth': 18, 'min_samples_split': 0.19710520305215856, 'min_samples_leaf': 0.19169814046139586}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:30,241] Trial 78 finished with value: 0.0 and parameters: {'n_estimators': 116, 'max_depth': 14, 'min_samples_split': 0.337554432355103, 'min_samples_leaf': 0.13081580417999678}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:30,900] Trial 79 finished with value: 0.0 and parameters: {'n_estimators': 200, 'max_depth': 29, 'min_samples_split': 0.7892695395561844, 'min_samples_leaf': 0.2863400924537891}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:32,472] Trial 80 finished with value: 0.0 and parameters: {'n_estimators': 271, 'max_depth': 24, 'min_samples_split': 0.5642138387762472, 'min_samples_leaf': 0.2111276668758408}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:33,872] Trial 81 finished with value: 0.0 and parameters: {'n_estimators': 462, 'max_depth': 8, 'min_samples_split': 0.17723853412269175, 'min_samples_leaf': 0.3712908616952265}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:35,941] Trial 82 finished with value: 0.0 and parameters: {'n_estimators': 491, 'max_depth': 3, 'min_samples_split': 0.1380162303140974, 'min_samples_leaf': 0.4170232780769723}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:37,727] Trial 83 finished with value: 0.0 and parameters: {'n_estimators': 367, 'max_depth': 9, 'min_samples_split': 0.2731516865011254, 'min_samples_leaf': 0.38060115155321783}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:39,023] Trial 84 finished with value: 0.0 and parameters: {'n_estimators': 427, 'max_depth': 5, 'min_samples_split': 0.22678905929505633, 'min_samples_leaf': 0.3983055108756699}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:40,526] Trial 85 finished with value: 0.0 and parameters: {'n_estimators': 499, 'max_depth': 30, 'min_samples_split': 0.18602875005028555, 'min_samples_leaf': 0.34987679519325265}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:41,261] Trial 86 finished with value: 0.0 and parameters: {'n_estimators': 226, 'max_depth': 6, 'min_samples_split': 0.2244574921231329, 'min_samples_leaf': 0.44957244594435186}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:42,733] Trial 87 finished with value: 0.0 and parameters: {'n_estimators': 241, 'max_depth': 10, 'min_samples_split': 0.4919249643595975, 'min_samples_leaf': 0.16023638998026513}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:43,795] Trial 88 finished with value: 0.0 and parameters: {'n_estimators': 345, 'max_depth': 20, 'min_samples_split': 0.825411771647119, 'min_samples_leaf': 0.27034051674573795}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:45,208] Trial 89 finished with value: 0.0 and parameters: {'n_estimators': 463, 'max_depth': 27, 'min_samples_split': 0.4693588841322949, 'min_samples_leaf': 0.3602213990131947}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:45,535] Trial 90 finished with value: 0.0 and parameters: {'n_estimators': 95, 'max_depth': 28, 'min_samples_split': 0.9996834702841562, 'min_samples_leaf': 0.4099837461133415}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:46,089] Trial 91 finished with value: 0.0 and parameters: {'n_estimators': 162, 'max_depth': 26, 'min_samples_split': 0.2815524897550918, 'min_samples_leaf': 0.4757687560634174}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:46,926] Trial 92 finished with value: 0.0 and parameters: {'n_estimators': 144, 'max_depth': 27, 'min_samples_split': 0.25012804153114154, 'min_samples_leaf': 0.30476987327325494}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:47,338] Trial 93 finished with value: 0.0 and parameters: {'n_estimators': 123, 'max_depth': 19, 'min_samples_split': 0.29525598002804565, 'min_samples_leaf': 0.4892347943857608}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:48,574] Trial 94 finished with value: 0.0 and parameters: {'n_estimators': 315, 'max_depth': 28, 'min_samples_split': 0.14672567121121244, 'min_samples_leaf': 0.4409203353067415}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:49,450] Trial 95 finished with value: 0.0 and parameters: {'n_estimators': 102, 'max_depth': 25, 'min_samples_split': 0.3233341352784499, 'min_samples_leaf': 0.25313774880616097}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:51,437] Trial 96 finished with value: 0.0 and parameters: {'n_estimators': 444, 'max_depth': 29, 'min_samples_split': 0.7189316372773501, 'min_samples_leaf': 0.3853624769687278}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:52,746] Trial 97 finished with value: 0.0 and parameters: {'n_estimators': 212, 'max_depth': 30, 'min_samples_split': 0.5305344610898932, 'min_samples_leaf': 0.12270673802019774}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:53,572] Trial 98 finished with value: 0.0 and parameters: {'n_estimators': 259, 'max_depth': 24, 'min_samples_split': 0.7600065773829499, 'min_samples_leaf': 0.2371462018334879}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:56,275] Trial 99 finished with value: 0.0 and parameters: {'n_estimators': 477, 'max_depth': 16, 'min_samples_split': 0.6267161007826235, 'min_samples_leaf': 0.20309407338380883}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-12-24 14:00:57,055] A new study created in memory with name: no-name-374c9e1f-5188-4edc-bc99-7514774e0b33\n",
      "[I 2023-12-24 14:00:57,419] Trial 0 finished with value: 0.042119565217391304 and parameters: {'num_leaves': 85, 'learning_rate': 0.023827122747091783, 'feature_fraction': 0.30036928454957074}. Best is trial 0 with value: 0.042119565217391304.\n",
      "[I 2023-12-24 14:00:58,200] Trial 1 finished with value: 0.23342175066312998 and parameters: {'num_leaves': 137, 'learning_rate': 0.04340820749969617, 'feature_fraction': 0.8177467723896182}. Best is trial 1 with value: 0.23342175066312998.\n",
      "[I 2023-12-24 14:00:58,485] Trial 2 finished with value: 0.18213058419243985 and parameters: {'num_leaves': 60, 'learning_rate': 0.0914762021462779, 'feature_fraction': 0.7375857562249439}. Best is trial 1 with value: 0.23342175066312998.\n",
      "[I 2023-12-24 14:00:59,145] Trial 3 finished with value: 0.244981986618631 and parameters: {'num_leaves': 132, 'learning_rate': 0.04886150734401962, 'feature_fraction': 0.4243303414165567}. Best is trial 3 with value: 0.244981986618631.\n",
      "[I 2023-12-24 14:00:59,572] Trial 4 finished with value: 0.0 and parameters: {'num_leaves': 66, 'learning_rate': 0.0033672360690759104, 'feature_fraction': 0.2858072625521729}. Best is trial 3 with value: 0.244981986618631.\n",
      "[I 2023-12-24 14:00:59,997] Trial 5 finished with value: 0.004243281471004244 and parameters: {'num_leaves': 32, 'learning_rate': 0.01393233062165047, 'feature_fraction': 0.9494466532067535}. Best is trial 3 with value: 0.244981986618631.\n",
      "[I 2023-12-24 14:01:00,570] Trial 6 finished with value: 0.19588202559821924 and parameters: {'num_leaves': 78, 'learning_rate': 0.04591713915709355, 'feature_fraction': 0.6913350095461485}. Best is trial 3 with value: 0.244981986618631.\n",
      "[I 2023-12-24 14:01:00,968] Trial 7 finished with value: 0.1438935912938331 and parameters: {'num_leaves': 77, 'learning_rate': 0.04305767445722128, 'feature_fraction': 0.13963804057910228}. Best is trial 3 with value: 0.244981986618631.\n",
      "[I 2023-12-24 14:01:01,297] Trial 8 finished with value: 0.013966480446927373 and parameters: {'num_leaves': 41, 'learning_rate': 0.023472869907238413, 'feature_fraction': 0.5216959796430688}. Best is trial 3 with value: 0.244981986618631.\n",
      "[I 2023-12-24 14:01:01,717] Trial 9 finished with value: 0.09284332688588008 and parameters: {'num_leaves': 23, 'learning_rate': 0.05057154693641548, 'feature_fraction': 0.5013514810243046}. Best is trial 3 with value: 0.244981986618631.\n",
      "[I 2023-12-24 14:01:01,925] Trial 10 finished with value: 0.0 and parameters: {'num_leaves': 146, 'learning_rate': 0.07928233428502518, 'feature_fraction': 0.36688562204490516}. Best is trial 3 with value: 0.244981986618631.\n",
      "[I 2023-12-24 14:01:02,980] Trial 11 finished with value: 0.25999999999999995 and parameters: {'num_leaves': 144, 'learning_rate': 0.0645908248921241, 'feature_fraction': 0.9711139153950796}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:03,753] Trial 12 finished with value: 0.2267163384779138 and parameters: {'num_leaves': 113, 'learning_rate': 0.06763871601981826, 'feature_fraction': 0.9785544712268459}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:04,084] Trial 13 finished with value: 0.047361299052774024 and parameters: {'num_leaves': 119, 'learning_rate': 0.06571419549506305, 'feature_fraction': 0.6244249425398392}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:04,843] Trial 14 finished with value: 0.24283480979676914 and parameters: {'num_leaves': 116, 'learning_rate': 0.06317805495347077, 'feature_fraction': 0.4300688921436276}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:05,344] Trial 15 finished with value: 0.2542713567839196 and parameters: {'num_leaves': 150, 'learning_rate': 0.09817393147840212, 'feature_fraction': 0.8454456513507117}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:05,718] Trial 16 finished with value: 0.21333333333333335 and parameters: {'num_leaves': 100, 'learning_rate': 0.0987331468447072, 'feature_fraction': 0.8588933792169846}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:06,181] Trial 17 finished with value: 0.2425819885476314 and parameters: {'num_leaves': 142, 'learning_rate': 0.0822962186884208, 'feature_fraction': 0.8685518185209172}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:06,572] Trial 18 finished with value: 0.21826039978390063 and parameters: {'num_leaves': 127, 'learning_rate': 0.07900505160159982, 'feature_fraction': 0.7861550798943746}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:07,022] Trial 19 finished with value: 0.2494824016563147 and parameters: {'num_leaves': 100, 'learning_rate': 0.09982374559685704, 'feature_fraction': 0.9947301569976822}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:07,451] Trial 20 finished with value: 0.24332648870636547 and parameters: {'num_leaves': 145, 'learning_rate': 0.08659711618536595, 'feature_fraction': 0.6146208665205094}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:07,845] Trial 21 finished with value: 0.23842469398616284 and parameters: {'num_leaves': 101, 'learning_rate': 0.09880863276731872, 'feature_fraction': 0.992163994530064}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:08,446] Trial 22 finished with value: 0.2595573440643863 and parameters: {'num_leaves': 149, 'learning_rate': 0.07404427912740968, 'feature_fraction': 0.9021824493434397}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:08,992] Trial 23 finished with value: 0.2344322344322344 and parameters: {'num_leaves': 148, 'learning_rate': 0.07070025639542833, 'feature_fraction': 0.9036953405116946}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:09,208] Trial 24 finished with value: 0.0 and parameters: {'num_leaves': 125, 'learning_rate': 0.05729492806935468, 'feature_fraction': 0.7711761228605556}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:09,664] Trial 25 finished with value: 0.2056277056277056 and parameters: {'num_leaves': 132, 'learning_rate': 0.0745154087800045, 'feature_fraction': 0.9005124050001105}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:09,936] Trial 26 finished with value: 0.0314207650273224 and parameters: {'num_leaves': 150, 'learning_rate': 0.05831615135354683, 'feature_fraction': 0.6725533332429117}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:10,375] Trial 27 finished with value: 0.2127429805615551 and parameters: {'num_leaves': 112, 'learning_rate': 0.08723298391461554, 'feature_fraction': 0.9198394441826925}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:11,133] Trial 28 finished with value: 0.2565150740929995 and parameters: {'num_leaves': 137, 'learning_rate': 0.05687064353918079, 'feature_fraction': 0.8156822034797508}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:11,370] Trial 29 finished with value: 0.002828854314002829 and parameters: {'num_leaves': 136, 'learning_rate': 0.05480658516306569, 'feature_fraction': 0.718816642914686}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:12,084] Trial 30 finished with value: 0.1571594877764843 and parameters: {'num_leaves': 90, 'learning_rate': 0.03042502993338691, 'feature_fraction': 0.8054269332576508}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:12,808] Trial 31 finished with value: 0.17873303167420815 and parameters: {'num_leaves': 138, 'learning_rate': 0.036236082979064436, 'feature_fraction': 0.8342014554739885}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:13,359] Trial 32 finished with value: 0.23854166666666668 and parameters: {'num_leaves': 124, 'learning_rate': 0.07439513516180463, 'feature_fraction': 0.9289223048112847}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:13,592] Trial 33 finished with value: 0.015352407536636428 and parameters: {'num_leaves': 136, 'learning_rate': 0.060448176487726844, 'feature_fraction': 0.8599288847501807}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:13,974] Trial 34 finished with value: 0.23974763406940067 and parameters: {'num_leaves': 149, 'learning_rate': 0.09138895435976234, 'feature_fraction': 0.7568254774967904}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:14,448] Trial 35 finished with value: 0.21948608137044961 and parameters: {'num_leaves': 129, 'learning_rate': 0.07095374071113518, 'feature_fraction': 0.8240745967456052}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:14,956] Trial 36 finished with value: 0.12165450121654503 and parameters: {'num_leaves': 53, 'learning_rate': 0.036653093372451394, 'feature_fraction': 0.637005269359107}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:16,061] Trial 37 finished with value: 0.23975090814737934 and parameters: {'num_leaves': 140, 'learning_rate': 0.05416370757020108, 'feature_fraction': 0.9481503543543253}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:16,525] Trial 38 finished with value: 0.2001093493712411 and parameters: {'num_leaves': 108, 'learning_rate': 0.09242176369840532, 'feature_fraction': 0.7314048317811758}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:16,884] Trial 39 finished with value: 0.011180992313067786 and parameters: {'num_leaves': 134, 'learning_rate': 0.04852482360565288, 'feature_fraction': 0.5653978772104304}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:17,145] Trial 40 finished with value: 0.01951219512195122 and parameters: {'num_leaves': 10, 'learning_rate': 0.06397296069198778, 'feature_fraction': 0.19791331171825738}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:17,675] Trial 41 finished with value: 0.21574973031283712 and parameters: {'num_leaves': 89, 'learning_rate': 0.09104544713515271, 'feature_fraction': 0.9992944284269036}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:18,208] Trial 42 finished with value: 0.23196151790486372 and parameters: {'num_leaves': 120, 'learning_rate': 0.09537776873556562, 'feature_fraction': 0.9485171224903388}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:18,633] Trial 43 finished with value: 0.18109790605546122 and parameters: {'num_leaves': 72, 'learning_rate': 0.0841926021546833, 'feature_fraction': 0.8781155354231162}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:19,057] Trial 44 finished with value: 0.2054945054945055 and parameters: {'num_leaves': 142, 'learning_rate': 0.07802683776068406, 'feature_fraction': 0.948123033499049}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:19,902] Trial 45 finished with value: 0.03026134800550206 and parameters: {'num_leaves': 106, 'learning_rate': 0.010889058850724498, 'feature_fraction': 0.997226980070013}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:20,219] Trial 46 finished with value: 0.205607476635514 and parameters: {'num_leaves': 96, 'learning_rate': 0.09631001910576893, 'feature_fraction': 0.8185624975626294}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:20,806] Trial 47 finished with value: 0.2568334192882929 and parameters: {'num_leaves': 150, 'learning_rate': 0.06812512754191614, 'feature_fraction': 0.89737583298444}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:21,752] Trial 48 finished with value: 0.24207792207792206 and parameters: {'num_leaves': 150, 'learning_rate': 0.04382136239823266, 'feature_fraction': 0.896069934599079}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:22,055] Trial 49 finished with value: 0.11185410334346504 and parameters: {'num_leaves': 142, 'learning_rate': 0.07102617512482517, 'feature_fraction': 0.7006989706639288}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:22,495] Trial 50 finished with value: 0.20572057205720573 and parameters: {'num_leaves': 130, 'learning_rate': 0.06749705985173923, 'feature_fraction': 0.8406542939024342}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:23,159] Trial 51 finished with value: 0.23326359832635984 and parameters: {'num_leaves': 139, 'learning_rate': 0.052352675619300446, 'feature_fraction': 0.9697299325496843}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:23,382] Trial 52 finished with value: 0.009831460674157305 and parameters: {'num_leaves': 144, 'learning_rate': 0.061829171071551774, 'feature_fraction': 0.9207458881214329}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:23,902] Trial 53 finished with value: 0.2408268733850129 and parameters: {'num_leaves': 122, 'learning_rate': 0.08142025410197469, 'feature_fraction': 0.7901190154754592}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:24,171] Trial 54 finished with value: 0.15558194774346795 and parameters: {'num_leaves': 60, 'learning_rate': 0.08795109647542956, 'feature_fraction': 0.8674642409226772}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:24,584] Trial 55 finished with value: 0.24305919329491882 and parameters: {'num_leaves': 133, 'learning_rate': 0.0996345264001744, 'feature_fraction': 0.9703077453738813}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:25,166] Trial 56 finished with value: 0.2548618219037871 and parameters: {'num_leaves': 145, 'learning_rate': 0.07486873824982415, 'feature_fraction': 0.8936668275422651}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:25,666] Trial 57 finished with value: 0.2494824016563147 and parameters: {'num_leaves': 145, 'learning_rate': 0.07758635313197405, 'feature_fraction': 0.890851389233823}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:25,953] Trial 58 finished with value: 0.12817412333736397 and parameters: {'num_leaves': 146, 'learning_rate': 0.06706359530114193, 'feature_fraction': 0.33790514226103013}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:26,548] Trial 59 finished with value: 0.2530612244897959 and parameters: {'num_leaves': 127, 'learning_rate': 0.058392966504203954, 'feature_fraction': 0.45006402302252296}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:26,717] Trial 60 finished with value: 0.0 and parameters: {'num_leaves': 150, 'learning_rate': 0.07427583655128724, 'feature_fraction': 0.752092788261026}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:27,277] Trial 61 finished with value: 0.24037460978147762 and parameters: {'num_leaves': 139, 'learning_rate': 0.05932819615158979, 'feature_fraction': 0.4469234959892627}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:27,499] Trial 62 finished with value: 0.03289924605894448 and parameters: {'num_leaves': 128, 'learning_rate': 0.06428702288548335, 'feature_fraction': 0.49240243032383746}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:27,781] Trial 63 finished with value: 0.03559206023271731 and parameters: {'num_leaves': 135, 'learning_rate': 0.049139215846486506, 'feature_fraction': 0.4615063158050344}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:28,342] Trial 64 finished with value: 0.23615464994775337 and parameters: {'num_leaves': 145, 'learning_rate': 0.05724098645186899, 'feature_fraction': 0.41575676196344985}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:28,916] Trial 65 finished with value: 0.23949579831932777 and parameters: {'num_leaves': 115, 'learning_rate': 0.0704103000142737, 'feature_fraction': 0.3936069186344328}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:29,230] Trial 66 finished with value: 0.050870147255689425 and parameters: {'num_leaves': 131, 'learning_rate': 0.07434461414078448, 'feature_fraction': 0.5410119093098703}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:30,141] Trial 67 finished with value: 0.220231822971549 and parameters: {'num_leaves': 139, 'learning_rate': 0.05588418095514135, 'feature_fraction': 0.8406730495720319}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:30,920] Trial 68 finished with value: 0.206598161168199 and parameters: {'num_leaves': 125, 'learning_rate': 0.06065936705911243, 'feature_fraction': 0.9172241977223003}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:31,315] Trial 69 finished with value: 0.08322496749024709 and parameters: {'num_leaves': 143, 'learning_rate': 0.052188398330389484, 'feature_fraction': 0.26320768061302546}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:31,637] Trial 70 finished with value: 0.020804438280166437 and parameters: {'num_leaves': 147, 'learning_rate': 0.06923662899326023, 'feature_fraction': 0.7786778837801442}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:32,258] Trial 71 finished with value: 0.23231256599788808 and parameters: {'num_leaves': 136, 'learning_rate': 0.08221079746808006, 'feature_fraction': 0.9650150389963481}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:32,424] Trial 72 finished with value: 0.0 and parameters: {'num_leaves': 149, 'learning_rate': 0.09574218408104415, 'feature_fraction': 0.9336964872868223}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:33,053] Trial 73 finished with value: 0.2378490175801448 and parameters: {'num_leaves': 140, 'learning_rate': 0.06583678146295818, 'feature_fraction': 0.8807274619524688}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:33,466] Trial 74 finished with value: 0.10972568578553615 and parameters: {'num_leaves': 40, 'learning_rate': 0.038587629527422534, 'feature_fraction': 0.5948840894562635}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:34,144] Trial 75 finished with value: 0.2462953500255493 and parameters: {'num_leaves': 132, 'learning_rate': 0.06289287301947907, 'feature_fraction': 0.8490532164446366}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:34,387] Trial 76 finished with value: 0.007037297677691766 and parameters: {'num_leaves': 126, 'learning_rate': 0.046644424319207727, 'feature_fraction': 0.9147643946258248}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:34,782] Trial 77 finished with value: 0.21985058697972248 and parameters: {'num_leaves': 84, 'learning_rate': 0.09333849150165004, 'feature_fraction': 0.800584205554084}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:34,987] Trial 78 finished with value: 0.02064693737095664 and parameters: {'num_leaves': 118, 'learning_rate': 0.0893377750211651, 'feature_fraction': 0.6582122651166609}. Best is trial 11 with value: 0.25999999999999995.\n",
      "[I 2023-12-24 14:01:35,568] Trial 79 finished with value: 0.26512096774193544 and parameters: {'num_leaves': 143, 'learning_rate': 0.07645761336942347, 'feature_fraction': 0.9826244870124671}. Best is trial 79 with value: 0.26512096774193544.\n",
      "[I 2023-12-24 14:01:36,099] Trial 80 finished with value: 0.25012607160867373 and parameters: {'num_leaves': 143, 'learning_rate': 0.0853640935893168, 'feature_fraction': 0.9425859230411436}. Best is trial 79 with value: 0.26512096774193544.\n",
      "[I 2023-12-24 14:01:36,485] Trial 81 finished with value: 0.21659482758620693 and parameters: {'num_leaves': 143, 'learning_rate': 0.08547153363607164, 'feature_fraction': 0.9389148955039344}. Best is trial 79 with value: 0.26512096774193544.\n",
      "[I 2023-12-24 14:01:37,055] Trial 82 finished with value: 0.23699124162802684 and parameters: {'num_leaves': 147, 'learning_rate': 0.07649320332817824, 'feature_fraction': 0.8915316710507989}. Best is trial 79 with value: 0.26512096774193544.\n",
      "[I 2023-12-24 14:01:37,590] Trial 83 finished with value: 0.24445590510572457 and parameters: {'num_leaves': 136, 'learning_rate': 0.0790215424423248, 'feature_fraction': 0.9789874634116935}. Best is trial 79 with value: 0.26512096774193544.\n",
      "[I 2023-12-24 14:01:38,205] Trial 84 finished with value: 0.25303643724696356 and parameters: {'num_leaves': 150, 'learning_rate': 0.07198078324491086, 'feature_fraction': 0.952366273316389}. Best is trial 79 with value: 0.26512096774193544.\n",
      "[I 2023-12-24 14:01:38,667] Trial 85 finished with value: 0.21837837837837842 and parameters: {'num_leaves': 149, 'learning_rate': 0.06903517112700891, 'feature_fraction': 0.8621928903044492}. Best is trial 79 with value: 0.26512096774193544.\n",
      "[I 2023-12-24 14:01:39,241] Trial 86 finished with value: 0.25064466219700876 and parameters: {'num_leaves': 140, 'learning_rate': 0.07213329163501683, 'feature_fraction': 0.9624885686650239}. Best is trial 79 with value: 0.26512096774193544.\n",
      "[I 2023-12-24 14:01:39,768] Trial 87 finished with value: 0.23008849557522124 and parameters: {'num_leaves': 147, 'learning_rate': 0.07273453740423336, 'feature_fraction': 0.9083998128046032}. Best is trial 79 with value: 0.26512096774193544.\n",
      "[I 2023-12-24 14:01:39,989] Trial 88 finished with value: 0.012596221133659902 and parameters: {'num_leaves': 150, 'learning_rate': 0.06503720805749409, 'feature_fraction': 0.8239039717474876}. Best is trial 79 with value: 0.26512096774193544.\n",
      "[I 2023-12-24 14:01:40,629] Trial 89 finished with value: 0.25931597753956104 and parameters: {'num_leaves': 134, 'learning_rate': 0.07598085901000819, 'feature_fraction': 0.9818104188583858}. Best is trial 79 with value: 0.26512096774193544.\n",
      "[I 2023-12-24 14:01:41,182] Trial 90 finished with value: 0.2659251769464105 and parameters: {'num_leaves': 134, 'learning_rate': 0.08002850669597583, 'feature_fraction': 0.9879470798614807}. Best is trial 90 with value: 0.2659251769464105.\n",
      "[I 2023-12-24 14:01:41,719] Trial 91 finished with value: 0.2384655261793676 and parameters: {'num_leaves': 134, 'learning_rate': 0.07627917958657046, 'feature_fraction': 0.9836042719770428}. Best is trial 90 with value: 0.2659251769464105.\n",
      "[I 2023-12-24 14:01:42,281] Trial 92 finished with value: 0.2488287350338365 and parameters: {'num_leaves': 130, 'learning_rate': 0.08113701150823453, 'feature_fraction': 0.997599395505077}. Best is trial 90 with value: 0.2659251769464105.\n",
      "[I 2023-12-24 14:01:43,065] Trial 93 finished with value: 0.26980942828485455 and parameters: {'num_leaves': 137, 'learning_rate': 0.08349612361719844, 'feature_fraction': 0.8810557608826248}. Best is trial 93 with value: 0.26980942828485455.\n",
      "[I 2023-12-24 14:01:43,691] Trial 94 finished with value: 0.23987375065754865 and parameters: {'num_leaves': 138, 'learning_rate': 0.08293289763727671, 'feature_fraction': 0.9267528609130473}. Best is trial 93 with value: 0.26980942828485455.\n",
      "[I 2023-12-24 14:01:44,376] Trial 95 finished with value: 0.22799575821845178 and parameters: {'num_leaves': 142, 'learning_rate': 0.07920816786304727, 'feature_fraction': 0.8779619999281286}. Best is trial 93 with value: 0.26980942828485455.\n",
      "[I 2023-12-24 14:01:45,271] Trial 96 finished with value: 0.26339509263895844 and parameters: {'num_leaves': 145, 'learning_rate': 0.07569862459821369, 'feature_fraction': 0.9740428105042721}. Best is trial 93 with value: 0.26980942828485455.\n",
      "[I 2023-12-24 14:01:45,936] Trial 97 finished with value: 0.243979057591623 and parameters: {'num_leaves': 137, 'learning_rate': 0.0741581142477144, 'feature_fraction': 0.9826659341666718}. Best is trial 93 with value: 0.26980942828485455.\n",
      "[I 2023-12-24 14:01:46,463] Trial 98 finished with value: 0.2575370464997445 and parameters: {'num_leaves': 123, 'learning_rate': 0.07986948493646603, 'feature_fraction': 0.9025195121099326}. Best is trial 93 with value: 0.26980942828485455.\n",
      "[I 2023-12-24 14:01:46,942] Trial 99 finished with value: 0.24511357633386158 and parameters: {'num_leaves': 123, 'learning_rate': 0.08078569874343056, 'feature_fraction': 0.9587502619908995}. Best is trial 93 with value: 0.26980942828485455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Info] Number of positive: 2837, number of negative: 8564\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 11401, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.248838 -> initscore=-1.104820\n",
      "[LightGBM] [Info] Start training from score -1.104820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-24 14:01:47,666] A new study created in memory with name: no-name-c8b9f30f-7a2a-4988-83b2-36a37bfe2a4f\n",
      "[I 2023-12-24 14:01:48,911] Trial 0 finished with value: 0.09230769230769231 and parameters: {'iterations': 453, 'learning_rate': 0.06407678858272994, 'depth': 5}. Best is trial 0 with value: 0.09230769230769231.\n",
      "[I 2023-12-24 14:01:50,337] Trial 1 finished with value: 0.0 and parameters: {'iterations': 278, 'learning_rate': 0.01560145713518813, 'depth': 4}. Best is trial 0 with value: 0.09230769230769231.\n",
      "[I 2023-12-24 14:01:51,614] Trial 2 finished with value: 0.08667529107373868 and parameters: {'iterations': 788, 'learning_rate': 0.05991978865520134, 'depth': 3}. Best is trial 0 with value: 0.09230769230769231.\n",
      "[I 2023-12-24 14:01:52,231] Trial 3 finished with value: 0.036960985626283374 and parameters: {'iterations': 103, 'learning_rate': 0.0772500202952413, 'depth': 6}. Best is trial 0 with value: 0.09230769230769231.\n",
      "[I 2023-12-24 14:01:52,624] Trial 4 finished with value: 0.011220196353436187 and parameters: {'iterations': 217, 'learning_rate': 0.09599902966676359, 'depth': 4}. Best is trial 0 with value: 0.09230769230769231.\n",
      "[I 2023-12-24 14:02:00,203] Trial 5 finished with value: 0.09572431397574983 and parameters: {'iterations': 379, 'learning_rate': 0.05023716438379445, 'depth': 10}. Best is trial 5 with value: 0.09572431397574983.\n",
      "[I 2023-12-24 14:02:04,670] Trial 6 finished with value: 0.13872135102533173 and parameters: {'iterations': 656, 'learning_rate': 0.0831962935814737, 'depth': 10}. Best is trial 6 with value: 0.13872135102533173.\n",
      "[I 2023-12-24 14:02:05,810] Trial 7 finished with value: 0.14345991561181434 and parameters: {'iterations': 708, 'learning_rate': 0.09415051677556119, 'depth': 4}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:02:08,550] Trial 8 finished with value: 0.09904761904761904 and parameters: {'iterations': 584, 'learning_rate': 0.032054491507872526, 'depth': 6}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:02:09,192] Trial 9 finished with value: 0.02888583218707015 and parameters: {'iterations': 103, 'learning_rate': 0.07249857598782287, 'depth': 6}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:02:13,121] Trial 10 finished with value: 0.10743285446595877 and parameters: {'iterations': 784, 'learning_rate': 0.095022863270356, 'depth': 9}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:02:15,291] Trial 11 finished with value: 0.12492345376607471 and parameters: {'iterations': 623, 'learning_rate': 0.08151233775668854, 'depth': 8}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:02:16,877] Trial 12 finished with value: 0.1230577998756992 and parameters: {'iterations': 652, 'learning_rate': 0.09943619667061047, 'depth': 8}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:02:22,762] Trial 13 finished with value: 0.08408796895213454 and parameters: {'iterations': 497, 'learning_rate': 0.04749096572369552, 'depth': 10}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:02:26,269] Trial 14 finished with value: 0.11698817672682016 and parameters: {'iterations': 698, 'learning_rate': 0.08711552593448413, 'depth': 8}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:02:27,639] Trial 15 finished with value: 0.11439346323067252 and parameters: {'iterations': 528, 'learning_rate': 0.06906403500371194, 'depth': 3}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:02:35,213] Trial 16 finished with value: 0.022237665045170257 and parameters: {'iterations': 706, 'learning_rate': 0.006326521097020588, 'depth': 7}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:02:36,061] Trial 17 finished with value: 0.08831168831168831 and parameters: {'iterations': 555, 'learning_rate': 0.08541278755692978, 'depth': 5}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:02:46,013] Trial 18 finished with value: 0.13341493268053856 and parameters: {'iterations': 712, 'learning_rate': 0.03302230959650111, 'depth': 9}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:02:48,155] Trial 19 finished with value: 0.12553846153846152 and parameters: {'iterations': 378, 'learning_rate': 0.05798258525343812, 'depth': 7}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:02:49,078] Trial 20 finished with value: 0.1085173501577287 and parameters: {'iterations': 652, 'learning_rate': 0.08791353948638848, 'depth': 4}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:02:57,516] Trial 21 finished with value: 0.10420590081607031 and parameters: {'iterations': 725, 'learning_rate': 0.03438255016442916, 'depth': 9}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:03:02,854] Trial 22 finished with value: 0.06008010680907877 and parameters: {'iterations': 735, 'learning_rate': 0.031066904775680127, 'depth': 9}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:03:12,278] Trial 23 finished with value: 0.0916613621896881 and parameters: {'iterations': 600, 'learning_rate': 0.041012967971438906, 'depth': 10}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:03:23,829] Trial 24 finished with value: 0.06112956810631229 and parameters: {'iterations': 666, 'learning_rate': 0.017558156290017016, 'depth': 9}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:03:37,675] Trial 25 finished with value: 0.07236842105263158 and parameters: {'iterations': 800, 'learning_rate': 0.020758942831543913, 'depth': 10}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:03:40,997] Trial 26 finished with value: 0.10793650793650793 and parameters: {'iterations': 745, 'learning_rate': 0.043442538233888654, 'depth': 8}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:03:42,033] Trial 27 finished with value: 0.10414052697616061 and parameters: {'iterations': 499, 'learning_rate': 0.0910587672747593, 'depth': 5}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:03:43,725] Trial 28 finished with value: 0.1285627653123105 and parameters: {'iterations': 683, 'learning_rate': 0.07773337989063461, 'depth': 7}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:03:48,280] Trial 29 finished with value: 0.08796895213454076 and parameters: {'iterations': 467, 'learning_rate': 0.06349679144771506, 'depth': 9}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:03:51,508] Trial 30 finished with value: 0.06287625418060201 and parameters: {'iterations': 414, 'learning_rate': 0.06838699191739614, 'depth': 10}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:03:52,772] Trial 31 finished with value: 0.09213051823416507 and parameters: {'iterations': 675, 'learning_rate': 0.07933736062285125, 'depth': 7}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:03:54,210] Trial 32 finished with value: 0.09114249037227214 and parameters: {'iterations': 608, 'learning_rate': 0.05569731011394125, 'depth': 5}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:03:55,485] Trial 33 finished with value: 0.012605042016806723 and parameters: {'iterations': 755, 'learning_rate': 0.02452526173815277, 'depth': 3}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:03:56,785] Trial 34 finished with value: 0.08113329040566646 and parameters: {'iterations': 569, 'learning_rate': 0.07461624500447119, 'depth': 7}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:04:01,890] Trial 35 finished with value: 0.0014174344436569811 and parameters: {'iterations': 631, 'learning_rate': 0.007569618220885078, 'depth': 4}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:04:02,954] Trial 36 finished with value: 0.11793916821849783 and parameters: {'iterations': 754, 'learning_rate': 0.09484619682090692, 'depth': 6}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:04:04,875] Trial 37 finished with value: 0.11194968553459118 and parameters: {'iterations': 685, 'learning_rate': 0.08068068225348578, 'depth': 8}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:04:08,055] Trial 38 finished with value: 0.14175104228707566 and parameters: {'iterations': 323, 'learning_rate': 0.09184038271185455, 'depth': 9}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:04:10,409] Trial 39 finished with value: 0.10841121495327104 and parameters: {'iterations': 330, 'learning_rate': 0.0917234511294829, 'depth': 9}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:04:13,761] Trial 40 finished with value: 0.0676841406768414 and parameters: {'iterations': 271, 'learning_rate': 0.09964272320387853, 'depth': 10}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:04:16,906] Trial 41 finished with value: 0.08926261319534282 and parameters: {'iterations': 192, 'learning_rate': 0.08457278557177955, 'depth': 9}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:04:19,154] Trial 42 finished with value: 0.1156211562115621 and parameters: {'iterations': 287, 'learning_rate': 0.07439568961048573, 'depth': 8}. Best is trial 7 with value: 0.14345991561181434.\n",
      "[I 2023-12-24 14:04:24,929] Trial 43 finished with value: 0.16485403548941038 and parameters: {'iterations': 769, 'learning_rate': 0.09135197561431375, 'depth': 10}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:04:30,531] Trial 44 finished with value: 0.11771919068056408 and parameters: {'iterations': 771, 'learning_rate': 0.09190906181409997, 'depth': 10}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:04:34,998] Trial 45 finished with value: 0.13930950938824954 and parameters: {'iterations': 719, 'learning_rate': 0.09662611347562357, 'depth': 10}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:04:43,983] Trial 46 finished with value: 0.1344639612356148 and parameters: {'iterations': 152, 'learning_rate': 0.09995361185263751, 'depth': 10}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:04:48,076] Trial 47 finished with value: 0.12560975609756098 and parameters: {'iterations': 792, 'learning_rate': 0.09375703386591297, 'depth': 10}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:04:52,819] Trial 48 finished with value: 0.12523020257826886 and parameters: {'iterations': 640, 'learning_rate': 0.08487510491326698, 'depth': 10}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:04:57,202] Trial 49 finished with value: 0.13030116779348494 and parameters: {'iterations': 347, 'learning_rate': 0.0893769519218702, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:01,155] Trial 50 finished with value: 0.13818181818181818 and parameters: {'iterations': 548, 'learning_rate': 0.09640331257048536, 'depth': 10}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:04,604] Trial 51 finished with value: 0.12315270935960591 and parameters: {'iterations': 524, 'learning_rate': 0.09803652704746911, 'depth': 10}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:10,732] Trial 52 finished with value: 0.11887254901960784 and parameters: {'iterations': 710, 'learning_rate': 0.0828753085189031, 'depth': 10}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:14,159] Trial 53 finished with value: 0.14472123368920523 and parameters: {'iterations': 450, 'learning_rate': 0.09564549784502625, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:17,339] Trial 54 finished with value: 0.14174174174174176 and parameters: {'iterations': 466, 'learning_rate': 0.08810567237600402, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:21,430] Trial 55 finished with value: 0.1399276236429433 and parameters: {'iterations': 449, 'learning_rate': 0.08825485017984828, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:24,563] Trial 56 finished with value: 0.15429917550058891 and parameters: {'iterations': 434, 'learning_rate': 0.08657696998590404, 'depth': 8}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:27,161] Trial 57 finished with value: 0.13528336380255943 and parameters: {'iterations': 419, 'learning_rate': 0.07023166640784656, 'depth': 8}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:29,197] Trial 58 finished with value: 0.11866501854140916 and parameters: {'iterations': 374, 'learning_rate': 0.08748004025288805, 'depth': 8}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:32,328] Trial 59 finished with value: 0.13780707010185742 and parameters: {'iterations': 295, 'learning_rate': 0.09334691089300447, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:36,803] Trial 60 finished with value: 0.10282131661442008 and parameters: {'iterations': 420, 'learning_rate': 0.08165177895778687, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:39,414] Trial 61 finished with value: 0.12106238418777023 and parameters: {'iterations': 479, 'learning_rate': 0.08897207481023246, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:41,480] Trial 62 finished with value: 0.1293471629042099 and parameters: {'iterations': 437, 'learning_rate': 0.08676375385640628, 'depth': 8}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:44,395] Trial 63 finished with value: 0.13905683192261184 and parameters: {'iterations': 454, 'learning_rate': 0.0907962401447426, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:48,671] Trial 64 finished with value: 0.10952084629744867 and parameters: {'iterations': 397, 'learning_rate': 0.07789222385601026, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:50,445] Trial 65 finished with value: 0.07611548556430446 and parameters: {'iterations': 257, 'learning_rate': 0.094596152466032, 'depth': 8}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:53,923] Trial 66 finished with value: 0.1330137807070102 and parameters: {'iterations': 511, 'learning_rate': 0.08380644748471185, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:55,498] Trial 67 finished with value: 0.0951776649746193 and parameters: {'iterations': 342, 'learning_rate': 0.0877447493296309, 'depth': 8}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:55,981] Trial 68 finished with value: 0.01262272089761571 and parameters: {'iterations': 479, 'learning_rate': 0.06494556413223378, 'depth': 3}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:56,800] Trial 69 finished with value: 0.055218855218855216 and parameters: {'iterations': 439, 'learning_rate': 0.07628199053851681, 'depth': 6}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:57,053] Trial 70 finished with value: 0.0014174344436569811 and parameters: {'iterations': 308, 'learning_rate': 0.09665712830173402, 'depth': 4}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:05:59,883] Trial 71 finished with value: 0.13114754098360654 and parameters: {'iterations': 226, 'learning_rate': 0.0963237035543468, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:03,505] Trial 72 finished with value: 0.08258064516129032 and parameters: {'iterations': 370, 'learning_rate': 0.0926272759957736, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:07,748] Trial 73 finished with value: 0.11369193154034231 and parameters: {'iterations': 764, 'learning_rate': 0.08979499389160034, 'depth': 10}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:12,067] Trial 74 finished with value: 0.13293413173652693 and parameters: {'iterations': 721, 'learning_rate': 0.09752332077596051, 'depth': 10}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:14,057] Trial 75 finished with value: 0.15449101796407186 and parameters: {'iterations': 488, 'learning_rate': 0.08561801738517083, 'depth': 7}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:16,641] Trial 76 finished with value: 0.10824417872876022 and parameters: {'iterations': 395, 'learning_rate': 0.08012193925930461, 'depth': 7}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:17,758] Trial 77 finished with value: 0.06374501992031872 and parameters: {'iterations': 461, 'learning_rate': 0.08599432621597398, 'depth': 7}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:18,337] Trial 78 finished with value: 0.026315789473684213 and parameters: {'iterations': 548, 'learning_rate': 0.08172240853494221, 'depth': 6}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:20,467] Trial 79 finished with value: 0.14616755793226383 and parameters: {'iterations': 497, 'learning_rate': 0.09155724203954893, 'depth': 8}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:22,073] Trial 80 finished with value: 0.10888610763454318 and parameters: {'iterations': 499, 'learning_rate': 0.09262231482802731, 'depth': 8}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:23,264] Trial 81 finished with value: 0.07832898172323761 and parameters: {'iterations': 517, 'learning_rate': 0.08540999368132163, 'depth': 8}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:24,212] Trial 82 finished with value: 0.06472919418758256 and parameters: {'iterations': 440, 'learning_rate': 0.08848528795521986, 'depth': 7}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:25,793] Trial 83 finished with value: 0.13035606517803258 and parameters: {'iterations': 469, 'learning_rate': 0.09030647442505473, 'depth': 7}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:26,814] Trial 84 finished with value: 0.11062225015713388 and parameters: {'iterations': 579, 'learning_rate': 0.0936019711475346, 'depth': 5}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:31,949] Trial 85 finished with value: 0.1316923076923077 and parameters: {'iterations': 494, 'learning_rate': 0.051523832264459744, 'depth': 8}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:34,855] Trial 86 finished with value: 0.14302884615384615 and parameters: {'iterations': 535, 'learning_rate': 0.09919555165895955, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:37,699] Trial 87 finished with value: 0.1390053924505692 and parameters: {'iterations': 601, 'learning_rate': 0.09956777830681732, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:38,920] Trial 88 finished with value: 0.0903225806451613 and parameters: {'iterations': 528, 'learning_rate': 0.09472256726819839, 'depth': 8}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:42,807] Trial 89 finished with value: 0.14147521160822246 and parameters: {'iterations': 398, 'learning_rate': 0.09766598753221614, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:44,750] Trial 90 finished with value: 0.12576312576312576 and parameters: {'iterations': 739, 'learning_rate': 0.09086935563208458, 'depth': 6}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:47,811] Trial 91 finished with value: 0.14991076740035694 and parameters: {'iterations': 426, 'learning_rate': 0.09729557713424584, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:50,832] Trial 92 finished with value: 0.140203714799281 and parameters: {'iterations': 483, 'learning_rate': 0.09437278164807754, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:53,460] Trial 93 finished with value: 0.1309090909090909 and parameters: {'iterations': 540, 'learning_rate': 0.09841995570004917, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:57,411] Trial 94 finished with value: 0.13978494623655913 and parameters: {'iterations': 423, 'learning_rate': 0.08403962927776935, 'depth': 8}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:06:59,979] Trial 95 finished with value: 0.11283323000619962 and parameters: {'iterations': 566, 'learning_rate': 0.09142928833746519, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:07:01,110] Trial 96 finished with value: 0.07485226526592254 and parameters: {'iterations': 358, 'learning_rate': 0.09447337492640266, 'depth': 8}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:07:02,722] Trial 97 finished with value: 0.06303348653972422 and parameters: {'iterations': 776, 'learning_rate': 0.09965532567740666, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:07:16,260] Trial 98 finished with value: 0.0 and parameters: {'iterations': 400, 'learning_rate': 0.001349592662757207, 'depth': 9}. Best is trial 43 with value: 0.16485403548941038.\n",
      "[I 2023-12-24 14:07:17,582] Trial 99 finished with value: 0.09993674889310562 and parameters: {'iterations': 506, 'learning_rate': 0.08727999403724487, 'depth': 7}. Best is trial 43 with value: 0.16485403548941038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6537461\ttotal: 45.3ms\tremaining: 34.8s\n",
      "1:\tlearn: 0.6230218\ttotal: 94.7ms\tremaining: 36.3s\n",
      "2:\tlearn: 0.5984579\ttotal: 139ms\tremaining: 35.5s\n",
      "3:\tlearn: 0.5785333\ttotal: 186ms\tremaining: 35.6s\n",
      "4:\tlearn: 0.5628816\ttotal: 245ms\tremaining: 37.5s\n",
      "5:\tlearn: 0.5512543\ttotal: 309ms\tremaining: 39.3s\n",
      "6:\tlearn: 0.5402119\ttotal: 375ms\tremaining: 40.8s\n",
      "7:\tlearn: 0.5316446\ttotal: 442ms\tremaining: 42s\n",
      "8:\tlearn: 0.5253385\ttotal: 497ms\tremaining: 42s\n",
      "9:\tlearn: 0.5187397\ttotal: 544ms\tremaining: 41.3s\n",
      "10:\tlearn: 0.5135938\ttotal: 589ms\tremaining: 40.6s\n",
      "11:\tlearn: 0.5084591\ttotal: 634ms\tremaining: 40s\n",
      "12:\tlearn: 0.5032035\ttotal: 680ms\tremaining: 39.5s\n",
      "13:\tlearn: 0.5003154\ttotal: 730ms\tremaining: 39.4s\n",
      "14:\tlearn: 0.4971883\ttotal: 782ms\tremaining: 39.3s\n",
      "15:\tlearn: 0.4941569\ttotal: 842ms\tremaining: 39.6s\n",
      "16:\tlearn: 0.4916866\ttotal: 890ms\tremaining: 39.4s\n",
      "17:\tlearn: 0.4888609\ttotal: 940ms\tremaining: 39.2s\n",
      "18:\tlearn: 0.4864788\ttotal: 990ms\tremaining: 39.1s\n",
      "19:\tlearn: 0.4834837\ttotal: 1.04s\tremaining: 38.9s\n",
      "20:\tlearn: 0.4813890\ttotal: 1.08s\tremaining: 38.6s\n",
      "21:\tlearn: 0.4793399\ttotal: 1.13s\tremaining: 38.3s\n",
      "22:\tlearn: 0.4772628\ttotal: 1.18s\tremaining: 38.3s\n",
      "23:\tlearn: 0.4741169\ttotal: 1.23s\tremaining: 38.2s\n",
      "24:\tlearn: 0.4723217\ttotal: 1.28s\tremaining: 38s\n",
      "25:\tlearn: 0.4708432\ttotal: 1.32s\tremaining: 37.9s\n",
      "26:\tlearn: 0.4694227\ttotal: 1.37s\tremaining: 37.7s\n",
      "27:\tlearn: 0.4676689\ttotal: 1.43s\tremaining: 37.8s\n",
      "28:\tlearn: 0.4643647\ttotal: 1.48s\tremaining: 37.7s\n",
      "29:\tlearn: 0.4628400\ttotal: 1.52s\tremaining: 37.5s\n",
      "30:\tlearn: 0.4607066\ttotal: 1.57s\tremaining: 37.3s\n",
      "31:\tlearn: 0.4597274\ttotal: 1.61s\tremaining: 37.2s\n",
      "32:\tlearn: 0.4583372\ttotal: 1.66s\tremaining: 37.1s\n",
      "33:\tlearn: 0.4575355\ttotal: 1.71s\tremaining: 37s\n",
      "34:\tlearn: 0.4563506\ttotal: 1.76s\tremaining: 36.9s\n",
      "35:\tlearn: 0.4552382\ttotal: 1.8s\tremaining: 36.7s\n",
      "36:\tlearn: 0.4535210\ttotal: 1.86s\tremaining: 36.9s\n",
      "37:\tlearn: 0.4520220\ttotal: 1.92s\tremaining: 36.9s\n",
      "38:\tlearn: 0.4509345\ttotal: 1.97s\tremaining: 36.9s\n",
      "39:\tlearn: 0.4489381\ttotal: 2.02s\tremaining: 36.8s\n",
      "40:\tlearn: 0.4465452\ttotal: 2.06s\tremaining: 36.6s\n",
      "41:\tlearn: 0.4448777\ttotal: 2.12s\tremaining: 36.6s\n",
      "42:\tlearn: 0.4427974\ttotal: 2.16s\tremaining: 36.5s\n",
      "43:\tlearn: 0.4409347\ttotal: 2.22s\tremaining: 36.5s\n",
      "44:\tlearn: 0.4401711\ttotal: 2.26s\tremaining: 36.4s\n",
      "45:\tlearn: 0.4390488\ttotal: 2.31s\tremaining: 36.3s\n",
      "46:\tlearn: 0.4377209\ttotal: 2.36s\tremaining: 36.3s\n",
      "47:\tlearn: 0.4366172\ttotal: 2.41s\tremaining: 36.2s\n",
      "48:\tlearn: 0.4356349\ttotal: 2.46s\tremaining: 36.1s\n",
      "49:\tlearn: 0.4350859\ttotal: 2.51s\tremaining: 36s\n",
      "50:\tlearn: 0.4335616\ttotal: 2.55s\tremaining: 35.9s\n",
      "51:\tlearn: 0.4319039\ttotal: 2.6s\tremaining: 35.9s\n",
      "52:\tlearn: 0.4312284\ttotal: 2.65s\tremaining: 35.8s\n",
      "53:\tlearn: 0.4301989\ttotal: 2.7s\tremaining: 35.7s\n",
      "54:\tlearn: 0.4291328\ttotal: 2.75s\tremaining: 35.7s\n",
      "55:\tlearn: 0.4279048\ttotal: 2.79s\tremaining: 35.6s\n",
      "56:\tlearn: 0.4268306\ttotal: 2.84s\tremaining: 35.5s\n",
      "57:\tlearn: 0.4256632\ttotal: 2.9s\tremaining: 35.6s\n",
      "58:\tlearn: 0.4250042\ttotal: 2.95s\tremaining: 35.5s\n",
      "59:\tlearn: 0.4237403\ttotal: 3s\tremaining: 35.4s\n",
      "60:\tlearn: 0.4228560\ttotal: 3.04s\tremaining: 35.4s\n",
      "61:\tlearn: 0.4215430\ttotal: 3.1s\tremaining: 35.3s\n",
      "62:\tlearn: 0.4204694\ttotal: 3.14s\tremaining: 35.2s\n",
      "63:\tlearn: 0.4192950\ttotal: 3.19s\tremaining: 35.1s\n",
      "64:\tlearn: 0.4182276\ttotal: 3.24s\tremaining: 35.1s\n",
      "65:\tlearn: 0.4173290\ttotal: 3.29s\tremaining: 35.1s\n",
      "66:\tlearn: 0.4160537\ttotal: 3.34s\tremaining: 35s\n",
      "67:\tlearn: 0.4147949\ttotal: 3.39s\tremaining: 34.9s\n",
      "68:\tlearn: 0.4139025\ttotal: 3.43s\tremaining: 34.8s\n",
      "69:\tlearn: 0.4131049\ttotal: 3.48s\tremaining: 34.8s\n",
      "70:\tlearn: 0.4122293\ttotal: 3.54s\tremaining: 34.8s\n",
      "71:\tlearn: 0.4114739\ttotal: 3.58s\tremaining: 34.7s\n",
      "72:\tlearn: 0.4106269\ttotal: 3.63s\tremaining: 34.6s\n",
      "73:\tlearn: 0.4096321\ttotal: 3.67s\tremaining: 34.5s\n",
      "74:\tlearn: 0.4085163\ttotal: 3.72s\tremaining: 34.4s\n",
      "75:\tlearn: 0.4074982\ttotal: 3.77s\tremaining: 34.4s\n",
      "76:\tlearn: 0.4066263\ttotal: 3.86s\tremaining: 34.7s\n",
      "77:\tlearn: 0.4056392\ttotal: 3.95s\tremaining: 35s\n",
      "78:\tlearn: 0.4045192\ttotal: 4.03s\tremaining: 35.2s\n",
      "79:\tlearn: 0.4032325\ttotal: 4.11s\tremaining: 35.4s\n",
      "80:\tlearn: 0.4024143\ttotal: 4.19s\tremaining: 35.6s\n",
      "81:\tlearn: 0.4015633\ttotal: 4.29s\tremaining: 36s\n",
      "82:\tlearn: 0.4007870\ttotal: 4.38s\tremaining: 36.2s\n",
      "83:\tlearn: 0.4001339\ttotal: 4.47s\tremaining: 36.5s\n",
      "84:\tlearn: 0.3990410\ttotal: 4.58s\tremaining: 36.8s\n",
      "85:\tlearn: 0.3981158\ttotal: 4.67s\tremaining: 37.1s\n",
      "86:\tlearn: 0.3972822\ttotal: 4.76s\tremaining: 37.3s\n",
      "87:\tlearn: 0.3961707\ttotal: 4.86s\tremaining: 37.6s\n",
      "88:\tlearn: 0.3955015\ttotal: 4.96s\tremaining: 37.9s\n",
      "89:\tlearn: 0.3947961\ttotal: 5.04s\tremaining: 38s\n",
      "90:\tlearn: 0.3938454\ttotal: 5.14s\tremaining: 38.3s\n",
      "91:\tlearn: 0.3927269\ttotal: 5.24s\tremaining: 38.5s\n",
      "92:\tlearn: 0.3918149\ttotal: 5.33s\tremaining: 38.7s\n",
      "93:\tlearn: 0.3904290\ttotal: 5.43s\tremaining: 39s\n",
      "94:\tlearn: 0.3898645\ttotal: 5.53s\tremaining: 39.2s\n",
      "95:\tlearn: 0.3887665\ttotal: 5.62s\tremaining: 39.4s\n",
      "96:\tlearn: 0.3875456\ttotal: 5.72s\tremaining: 39.6s\n",
      "97:\tlearn: 0.3865002\ttotal: 5.82s\tremaining: 39.9s\n",
      "98:\tlearn: 0.3858442\ttotal: 5.9s\tremaining: 40s\n",
      "99:\tlearn: 0.3844156\ttotal: 6.01s\tremaining: 40.2s\n",
      "100:\tlearn: 0.3840259\ttotal: 6.1s\tremaining: 40.4s\n",
      "101:\tlearn: 0.3833375\ttotal: 6.2s\tremaining: 40.5s\n",
      "102:\tlearn: 0.3825003\ttotal: 6.28s\tremaining: 40.6s\n",
      "103:\tlearn: 0.3814292\ttotal: 6.38s\tremaining: 40.8s\n",
      "104:\tlearn: 0.3808357\ttotal: 6.46s\tremaining: 40.9s\n",
      "105:\tlearn: 0.3799935\ttotal: 6.55s\tremaining: 41s\n",
      "106:\tlearn: 0.3791361\ttotal: 6.63s\tremaining: 41s\n",
      "107:\tlearn: 0.3782426\ttotal: 6.7s\tremaining: 41s\n",
      "108:\tlearn: 0.3775397\ttotal: 6.79s\tremaining: 41.1s\n",
      "109:\tlearn: 0.3763444\ttotal: 6.86s\tremaining: 41.1s\n",
      "110:\tlearn: 0.3756487\ttotal: 6.93s\tremaining: 41.1s\n",
      "111:\tlearn: 0.3750029\ttotal: 7.05s\tremaining: 41.3s\n",
      "112:\tlearn: 0.3739596\ttotal: 7.11s\tremaining: 41.3s\n",
      "113:\tlearn: 0.3724491\ttotal: 7.2s\tremaining: 41.4s\n",
      "114:\tlearn: 0.3717134\ttotal: 7.29s\tremaining: 41.4s\n",
      "115:\tlearn: 0.3705125\ttotal: 7.36s\tremaining: 41.5s\n",
      "116:\tlearn: 0.3693477\ttotal: 7.43s\tremaining: 41.4s\n",
      "117:\tlearn: 0.3682360\ttotal: 7.48s\tremaining: 41.3s\n",
      "118:\tlearn: 0.3677323\ttotal: 7.54s\tremaining: 41.2s\n",
      "119:\tlearn: 0.3666705\ttotal: 7.59s\tremaining: 41s\n",
      "120:\tlearn: 0.3656178\ttotal: 7.64s\tremaining: 40.9s\n",
      "121:\tlearn: 0.3647838\ttotal: 7.68s\tremaining: 40.8s\n",
      "122:\tlearn: 0.3640691\ttotal: 7.73s\tremaining: 40.6s\n",
      "123:\tlearn: 0.3627536\ttotal: 7.78s\tremaining: 40.5s\n",
      "124:\tlearn: 0.3619539\ttotal: 7.83s\tremaining: 40.3s\n",
      "125:\tlearn: 0.3607408\ttotal: 7.88s\tremaining: 40.2s\n",
      "126:\tlearn: 0.3601955\ttotal: 7.93s\tremaining: 40.1s\n",
      "127:\tlearn: 0.3590843\ttotal: 7.98s\tremaining: 40s\n",
      "128:\tlearn: 0.3579015\ttotal: 8.03s\tremaining: 39.9s\n",
      "129:\tlearn: 0.3573871\ttotal: 8.09s\tremaining: 39.8s\n",
      "130:\tlearn: 0.3566082\ttotal: 8.14s\tremaining: 39.7s\n",
      "131:\tlearn: 0.3559332\ttotal: 8.2s\tremaining: 39.6s\n",
      "132:\tlearn: 0.3553182\ttotal: 8.24s\tremaining: 39.4s\n",
      "133:\tlearn: 0.3547441\ttotal: 8.29s\tremaining: 39.3s\n",
      "134:\tlearn: 0.3531859\ttotal: 8.34s\tremaining: 39.2s\n",
      "135:\tlearn: 0.3526146\ttotal: 8.38s\tremaining: 39s\n",
      "136:\tlearn: 0.3514236\ttotal: 8.44s\tremaining: 38.9s\n",
      "137:\tlearn: 0.3504194\ttotal: 8.48s\tremaining: 38.8s\n",
      "138:\tlearn: 0.3494910\ttotal: 8.53s\tremaining: 38.7s\n",
      "139:\tlearn: 0.3485151\ttotal: 8.58s\tremaining: 38.5s\n",
      "140:\tlearn: 0.3480001\ttotal: 8.62s\tremaining: 38.4s\n",
      "141:\tlearn: 0.3467221\ttotal: 8.68s\tremaining: 38.3s\n",
      "142:\tlearn: 0.3457915\ttotal: 8.73s\tremaining: 38.2s\n",
      "143:\tlearn: 0.3448516\ttotal: 8.78s\tremaining: 38.1s\n",
      "144:\tlearn: 0.3439313\ttotal: 8.82s\tremaining: 38s\n",
      "145:\tlearn: 0.3425650\ttotal: 8.87s\tremaining: 37.9s\n",
      "146:\tlearn: 0.3413221\ttotal: 8.92s\tremaining: 37.8s\n",
      "147:\tlearn: 0.3401684\ttotal: 8.98s\tremaining: 37.7s\n",
      "148:\tlearn: 0.3393235\ttotal: 9.03s\tremaining: 37.6s\n",
      "149:\tlearn: 0.3383137\ttotal: 9.08s\tremaining: 37.5s\n",
      "150:\tlearn: 0.3372997\ttotal: 9.14s\tremaining: 37.4s\n",
      "151:\tlearn: 0.3368302\ttotal: 9.19s\tremaining: 37.3s\n",
      "152:\tlearn: 0.3353515\ttotal: 9.25s\tremaining: 37.2s\n",
      "153:\tlearn: 0.3347572\ttotal: 9.29s\tremaining: 37.1s\n",
      "154:\tlearn: 0.3335412\ttotal: 9.34s\tremaining: 37s\n",
      "155:\tlearn: 0.3318748\ttotal: 9.39s\tremaining: 36.9s\n",
      "156:\tlearn: 0.3306236\ttotal: 9.44s\tremaining: 36.8s\n",
      "157:\tlearn: 0.3298283\ttotal: 9.49s\tremaining: 36.7s\n",
      "158:\tlearn: 0.3292117\ttotal: 9.53s\tremaining: 36.6s\n",
      "159:\tlearn: 0.3286140\ttotal: 9.58s\tremaining: 36.5s\n",
      "160:\tlearn: 0.3273625\ttotal: 9.63s\tremaining: 36.4s\n",
      "161:\tlearn: 0.3261122\ttotal: 9.68s\tremaining: 36.3s\n",
      "162:\tlearn: 0.3251816\ttotal: 9.73s\tremaining: 36.2s\n",
      "163:\tlearn: 0.3246115\ttotal: 9.78s\tremaining: 36.1s\n",
      "164:\tlearn: 0.3233964\ttotal: 9.82s\tremaining: 36s\n",
      "165:\tlearn: 0.3227464\ttotal: 9.88s\tremaining: 35.9s\n",
      "166:\tlearn: 0.3217009\ttotal: 9.92s\tremaining: 35.8s\n",
      "167:\tlearn: 0.3208177\ttotal: 9.98s\tremaining: 35.7s\n",
      "168:\tlearn: 0.3203274\ttotal: 10s\tremaining: 35.6s\n",
      "169:\tlearn: 0.3196004\ttotal: 10.1s\tremaining: 35.5s\n",
      "170:\tlearn: 0.3182023\ttotal: 10.1s\tremaining: 35.5s\n",
      "171:\tlearn: 0.3175174\ttotal: 10.2s\tremaining: 35.4s\n",
      "172:\tlearn: 0.3164594\ttotal: 10.2s\tremaining: 35.3s\n",
      "173:\tlearn: 0.3157250\ttotal: 10.3s\tremaining: 35.2s\n",
      "174:\tlearn: 0.3149722\ttotal: 10.3s\tremaining: 35.1s\n",
      "175:\tlearn: 0.3138278\ttotal: 10.4s\tremaining: 35s\n",
      "176:\tlearn: 0.3127044\ttotal: 10.4s\tremaining: 34.9s\n",
      "177:\tlearn: 0.3120439\ttotal: 10.5s\tremaining: 34.8s\n",
      "178:\tlearn: 0.3113670\ttotal: 10.5s\tremaining: 34.7s\n",
      "179:\tlearn: 0.3106889\ttotal: 10.6s\tremaining: 34.6s\n",
      "180:\tlearn: 0.3097623\ttotal: 10.6s\tremaining: 34.5s\n",
      "181:\tlearn: 0.3090336\ttotal: 10.7s\tremaining: 34.4s\n",
      "182:\tlearn: 0.3084217\ttotal: 10.7s\tremaining: 34.3s\n",
      "183:\tlearn: 0.3078361\ttotal: 10.8s\tremaining: 34.2s\n",
      "184:\tlearn: 0.3066567\ttotal: 10.8s\tremaining: 34.1s\n",
      "185:\tlearn: 0.3059762\ttotal: 10.9s\tremaining: 34s\n",
      "186:\tlearn: 0.3049555\ttotal: 10.9s\tremaining: 33.9s\n",
      "187:\tlearn: 0.3042665\ttotal: 11s\tremaining: 33.9s\n",
      "188:\tlearn: 0.3035056\ttotal: 11s\tremaining: 33.8s\n",
      "189:\tlearn: 0.3026376\ttotal: 11.1s\tremaining: 33.7s\n",
      "190:\tlearn: 0.3019006\ttotal: 11.1s\tremaining: 33.6s\n",
      "191:\tlearn: 0.3014570\ttotal: 11.2s\tremaining: 33.6s\n",
      "192:\tlearn: 0.3003533\ttotal: 11.2s\tremaining: 33.5s\n",
      "193:\tlearn: 0.2995245\ttotal: 11.3s\tremaining: 33.4s\n",
      "194:\tlearn: 0.2987307\ttotal: 11.3s\tremaining: 33.3s\n",
      "195:\tlearn: 0.2976329\ttotal: 11.4s\tremaining: 33.2s\n",
      "196:\tlearn: 0.2974065\ttotal: 11.4s\tremaining: 33.2s\n",
      "197:\tlearn: 0.2969981\ttotal: 11.5s\tremaining: 33.1s\n",
      "198:\tlearn: 0.2962256\ttotal: 11.5s\tremaining: 33s\n",
      "199:\tlearn: 0.2951572\ttotal: 11.6s\tremaining: 32.9s\n",
      "200:\tlearn: 0.2944774\ttotal: 11.6s\tremaining: 32.8s\n",
      "201:\tlearn: 0.2937156\ttotal: 11.7s\tremaining: 32.7s\n",
      "202:\tlearn: 0.2931693\ttotal: 11.7s\tremaining: 32.7s\n",
      "203:\tlearn: 0.2924489\ttotal: 11.8s\tremaining: 32.6s\n",
      "204:\tlearn: 0.2916044\ttotal: 11.8s\tremaining: 32.5s\n",
      "205:\tlearn: 0.2907705\ttotal: 11.9s\tremaining: 32.4s\n",
      "206:\tlearn: 0.2904547\ttotal: 11.9s\tremaining: 32.4s\n",
      "207:\tlearn: 0.2896622\ttotal: 12s\tremaining: 32.3s\n",
      "208:\tlearn: 0.2884631\ttotal: 12s\tremaining: 32.2s\n",
      "209:\tlearn: 0.2877476\ttotal: 12.1s\tremaining: 32.1s\n",
      "210:\tlearn: 0.2871985\ttotal: 12.1s\tremaining: 32.1s\n",
      "211:\tlearn: 0.2864843\ttotal: 12.2s\tremaining: 32s\n",
      "212:\tlearn: 0.2859540\ttotal: 12.2s\tremaining: 32s\n",
      "213:\tlearn: 0.2851228\ttotal: 12.3s\tremaining: 31.9s\n",
      "214:\tlearn: 0.2845019\ttotal: 12.3s\tremaining: 31.8s\n",
      "215:\tlearn: 0.2839170\ttotal: 12.4s\tremaining: 31.7s\n",
      "216:\tlearn: 0.2825668\ttotal: 12.4s\tremaining: 31.7s\n",
      "217:\tlearn: 0.2811186\ttotal: 12.5s\tremaining: 31.6s\n",
      "218:\tlearn: 0.2805319\ttotal: 12.5s\tremaining: 31.5s\n",
      "219:\tlearn: 0.2796631\ttotal: 12.6s\tremaining: 31.4s\n",
      "220:\tlearn: 0.2790446\ttotal: 12.6s\tremaining: 31.3s\n",
      "221:\tlearn: 0.2782243\ttotal: 12.7s\tremaining: 31.3s\n",
      "222:\tlearn: 0.2775504\ttotal: 12.7s\tremaining: 31.2s\n",
      "223:\tlearn: 0.2769179\ttotal: 12.8s\tremaining: 31.1s\n",
      "224:\tlearn: 0.2763169\ttotal: 12.8s\tremaining: 31s\n",
      "225:\tlearn: 0.2754344\ttotal: 12.9s\tremaining: 31s\n",
      "226:\tlearn: 0.2746999\ttotal: 13s\tremaining: 31s\n",
      "227:\tlearn: 0.2739509\ttotal: 13s\tremaining: 30.9s\n",
      "228:\tlearn: 0.2734398\ttotal: 13.1s\tremaining: 30.9s\n",
      "229:\tlearn: 0.2728292\ttotal: 13.1s\tremaining: 30.8s\n",
      "230:\tlearn: 0.2723965\ttotal: 13.2s\tremaining: 30.8s\n",
      "231:\tlearn: 0.2719037\ttotal: 13.3s\tremaining: 30.8s\n",
      "232:\tlearn: 0.2712443\ttotal: 13.3s\tremaining: 30.7s\n",
      "233:\tlearn: 0.2708097\ttotal: 13.4s\tremaining: 30.6s\n",
      "234:\tlearn: 0.2704892\ttotal: 13.4s\tremaining: 30.6s\n",
      "235:\tlearn: 0.2697049\ttotal: 13.5s\tremaining: 30.5s\n",
      "236:\tlearn: 0.2686289\ttotal: 13.5s\tremaining: 30.4s\n",
      "237:\tlearn: 0.2680353\ttotal: 13.6s\tremaining: 30.3s\n",
      "238:\tlearn: 0.2674002\ttotal: 13.6s\tremaining: 30.3s\n",
      "239:\tlearn: 0.2669649\ttotal: 13.7s\tremaining: 30.2s\n",
      "240:\tlearn: 0.2663153\ttotal: 13.7s\tremaining: 30.1s\n",
      "241:\tlearn: 0.2656803\ttotal: 13.8s\tremaining: 30s\n",
      "242:\tlearn: 0.2651202\ttotal: 13.8s\tremaining: 30s\n",
      "243:\tlearn: 0.2639885\ttotal: 13.9s\tremaining: 29.9s\n",
      "244:\tlearn: 0.2630144\ttotal: 13.9s\tremaining: 29.8s\n",
      "245:\tlearn: 0.2620629\ttotal: 14s\tremaining: 29.7s\n",
      "246:\tlearn: 0.2614730\ttotal: 14s\tremaining: 29.7s\n",
      "247:\tlearn: 0.2606294\ttotal: 14.1s\tremaining: 29.6s\n",
      "248:\tlearn: 0.2601774\ttotal: 14.1s\tremaining: 29.5s\n",
      "249:\tlearn: 0.2595288\ttotal: 14.2s\tremaining: 29.5s\n",
      "250:\tlearn: 0.2590162\ttotal: 14.2s\tremaining: 29.4s\n",
      "251:\tlearn: 0.2584353\ttotal: 14.3s\tremaining: 29.3s\n",
      "252:\tlearn: 0.2574203\ttotal: 14.3s\tremaining: 29.2s\n",
      "253:\tlearn: 0.2569242\ttotal: 14.4s\tremaining: 29.2s\n",
      "254:\tlearn: 0.2565241\ttotal: 14.4s\tremaining: 29.1s\n",
      "255:\tlearn: 0.2557303\ttotal: 14.5s\tremaining: 29s\n",
      "256:\tlearn: 0.2549160\ttotal: 14.5s\tremaining: 28.9s\n",
      "257:\tlearn: 0.2546624\ttotal: 14.6s\tremaining: 28.9s\n",
      "258:\tlearn: 0.2540942\ttotal: 14.6s\tremaining: 28.8s\n",
      "259:\tlearn: 0.2532606\ttotal: 14.7s\tremaining: 28.7s\n",
      "260:\tlearn: 0.2526315\ttotal: 14.7s\tremaining: 28.6s\n",
      "261:\tlearn: 0.2521929\ttotal: 14.8s\tremaining: 28.6s\n",
      "262:\tlearn: 0.2515033\ttotal: 14.8s\tremaining: 28.5s\n",
      "263:\tlearn: 0.2510087\ttotal: 14.9s\tremaining: 28.4s\n",
      "264:\tlearn: 0.2498549\ttotal: 14.9s\tremaining: 28.4s\n",
      "265:\tlearn: 0.2493379\ttotal: 15s\tremaining: 28.3s\n",
      "266:\tlearn: 0.2487680\ttotal: 15s\tremaining: 28.2s\n",
      "267:\tlearn: 0.2483426\ttotal: 15.1s\tremaining: 28.2s\n",
      "268:\tlearn: 0.2477587\ttotal: 15.1s\tremaining: 28.1s\n",
      "269:\tlearn: 0.2470106\ttotal: 15.2s\tremaining: 28s\n",
      "270:\tlearn: 0.2463682\ttotal: 15.2s\tremaining: 27.9s\n",
      "271:\tlearn: 0.2457937\ttotal: 15.3s\tremaining: 27.9s\n",
      "272:\tlearn: 0.2453937\ttotal: 15.3s\tremaining: 27.8s\n",
      "273:\tlearn: 0.2449176\ttotal: 15.4s\tremaining: 27.8s\n",
      "274:\tlearn: 0.2442946\ttotal: 15.4s\tremaining: 27.7s\n",
      "275:\tlearn: 0.2439033\ttotal: 15.5s\tremaining: 27.6s\n",
      "276:\tlearn: 0.2436308\ttotal: 15.5s\tremaining: 27.6s\n",
      "277:\tlearn: 0.2428374\ttotal: 15.6s\tremaining: 27.5s\n",
      "278:\tlearn: 0.2422245\ttotal: 15.6s\tremaining: 27.4s\n",
      "279:\tlearn: 0.2419873\ttotal: 15.7s\tremaining: 27.4s\n",
      "280:\tlearn: 0.2415006\ttotal: 15.7s\tremaining: 27.3s\n",
      "281:\tlearn: 0.2407344\ttotal: 15.8s\tremaining: 27.2s\n",
      "282:\tlearn: 0.2400636\ttotal: 15.8s\tremaining: 27.2s\n",
      "283:\tlearn: 0.2394029\ttotal: 15.9s\tremaining: 27.1s\n",
      "284:\tlearn: 0.2386884\ttotal: 15.9s\tremaining: 27s\n",
      "285:\tlearn: 0.2382634\ttotal: 16s\tremaining: 27s\n",
      "286:\tlearn: 0.2373995\ttotal: 16s\tremaining: 26.9s\n",
      "287:\tlearn: 0.2370979\ttotal: 16.1s\tremaining: 26.8s\n",
      "288:\tlearn: 0.2366780\ttotal: 16.1s\tremaining: 26.8s\n",
      "289:\tlearn: 0.2363182\ttotal: 16.2s\tremaining: 26.7s\n",
      "290:\tlearn: 0.2354862\ttotal: 16.2s\tremaining: 26.6s\n",
      "291:\tlearn: 0.2346563\ttotal: 16.3s\tremaining: 26.6s\n",
      "292:\tlearn: 0.2342653\ttotal: 16.3s\tremaining: 26.5s\n",
      "293:\tlearn: 0.2333455\ttotal: 16.4s\tremaining: 26.5s\n",
      "294:\tlearn: 0.2329691\ttotal: 16.4s\tremaining: 26.4s\n",
      "295:\tlearn: 0.2320567\ttotal: 16.5s\tremaining: 26.3s\n",
      "296:\tlearn: 0.2313593\ttotal: 16.5s\tremaining: 26.3s\n",
      "297:\tlearn: 0.2309531\ttotal: 16.6s\tremaining: 26.2s\n",
      "298:\tlearn: 0.2301764\ttotal: 16.6s\tremaining: 26.1s\n",
      "299:\tlearn: 0.2296698\ttotal: 16.7s\tremaining: 26.1s\n",
      "300:\tlearn: 0.2291306\ttotal: 16.7s\tremaining: 26s\n",
      "301:\tlearn: 0.2282536\ttotal: 16.8s\tremaining: 25.9s\n",
      "302:\tlearn: 0.2277841\ttotal: 16.8s\tremaining: 25.9s\n",
      "303:\tlearn: 0.2271996\ttotal: 16.9s\tremaining: 25.8s\n",
      "304:\tlearn: 0.2266670\ttotal: 16.9s\tremaining: 25.7s\n",
      "305:\tlearn: 0.2259795\ttotal: 17s\tremaining: 25.7s\n",
      "306:\tlearn: 0.2253858\ttotal: 17s\tremaining: 25.6s\n",
      "307:\tlearn: 0.2246292\ttotal: 17.1s\tremaining: 25.6s\n",
      "308:\tlearn: 0.2240258\ttotal: 17.1s\tremaining: 25.5s\n",
      "309:\tlearn: 0.2233606\ttotal: 17.2s\tremaining: 25.4s\n",
      "310:\tlearn: 0.2229003\ttotal: 17.2s\tremaining: 25.4s\n",
      "311:\tlearn: 0.2225931\ttotal: 17.3s\tremaining: 25.3s\n",
      "312:\tlearn: 0.2220929\ttotal: 17.3s\tremaining: 25.3s\n",
      "313:\tlearn: 0.2217434\ttotal: 17.4s\tremaining: 25.3s\n",
      "314:\tlearn: 0.2210259\ttotal: 17.5s\tremaining: 25.3s\n",
      "315:\tlearn: 0.2208301\ttotal: 17.6s\tremaining: 25.3s\n",
      "316:\tlearn: 0.2201431\ttotal: 17.7s\tremaining: 25.2s\n",
      "317:\tlearn: 0.2199024\ttotal: 17.8s\tremaining: 25.2s\n",
      "318:\tlearn: 0.2195401\ttotal: 17.9s\tremaining: 25.2s\n",
      "319:\tlearn: 0.2189752\ttotal: 18s\tremaining: 25.2s\n",
      "320:\tlearn: 0.2180138\ttotal: 18.1s\tremaining: 25.2s\n",
      "321:\tlearn: 0.2174809\ttotal: 18.2s\tremaining: 25.2s\n",
      "322:\tlearn: 0.2170121\ttotal: 18.3s\tremaining: 25.2s\n",
      "323:\tlearn: 0.2164958\ttotal: 18.3s\tremaining: 25.2s\n",
      "324:\tlearn: 0.2160898\ttotal: 18.4s\tremaining: 25.2s\n",
      "325:\tlearn: 0.2157483\ttotal: 18.5s\tremaining: 25.2s\n",
      "326:\tlearn: 0.2151974\ttotal: 18.6s\tremaining: 25.2s\n",
      "327:\tlearn: 0.2146685\ttotal: 18.7s\tremaining: 25.2s\n",
      "328:\tlearn: 0.2142376\ttotal: 18.8s\tremaining: 25.1s\n",
      "329:\tlearn: 0.2137523\ttotal: 18.9s\tremaining: 25.1s\n",
      "330:\tlearn: 0.2134693\ttotal: 19s\tremaining: 25.1s\n",
      "331:\tlearn: 0.2131469\ttotal: 19.1s\tremaining: 25.1s\n",
      "332:\tlearn: 0.2124477\ttotal: 19.2s\tremaining: 25.1s\n",
      "333:\tlearn: 0.2117684\ttotal: 19.3s\tremaining: 25.1s\n",
      "334:\tlearn: 0.2113767\ttotal: 19.4s\tremaining: 25.1s\n",
      "335:\tlearn: 0.2108693\ttotal: 19.5s\tremaining: 25.1s\n",
      "336:\tlearn: 0.2104369\ttotal: 19.5s\tremaining: 25.1s\n",
      "337:\tlearn: 0.2101624\ttotal: 19.6s\tremaining: 25s\n",
      "338:\tlearn: 0.2096499\ttotal: 19.7s\tremaining: 25s\n",
      "339:\tlearn: 0.2091466\ttotal: 19.8s\tremaining: 25s\n",
      "340:\tlearn: 0.2087491\ttotal: 19.9s\tremaining: 25s\n",
      "341:\tlearn: 0.2082287\ttotal: 20s\tremaining: 25s\n",
      "342:\tlearn: 0.2074949\ttotal: 20.1s\tremaining: 25s\n",
      "343:\tlearn: 0.2069874\ttotal: 20.2s\tremaining: 25s\n",
      "344:\tlearn: 0.2063589\ttotal: 20.3s\tremaining: 24.9s\n",
      "345:\tlearn: 0.2058491\ttotal: 20.4s\tremaining: 24.9s\n",
      "346:\tlearn: 0.2053736\ttotal: 20.5s\tremaining: 24.9s\n",
      "347:\tlearn: 0.2047037\ttotal: 20.5s\tremaining: 24.9s\n",
      "348:\tlearn: 0.2042502\ttotal: 20.6s\tremaining: 24.8s\n",
      "349:\tlearn: 0.2037575\ttotal: 20.7s\tremaining: 24.8s\n",
      "350:\tlearn: 0.2032110\ttotal: 20.8s\tremaining: 24.8s\n",
      "351:\tlearn: 0.2027763\ttotal: 20.9s\tremaining: 24.7s\n",
      "352:\tlearn: 0.2021957\ttotal: 21s\tremaining: 24.7s\n",
      "353:\tlearn: 0.2017599\ttotal: 21s\tremaining: 24.6s\n",
      "354:\tlearn: 0.2013464\ttotal: 21.1s\tremaining: 24.6s\n",
      "355:\tlearn: 0.2006563\ttotal: 21.1s\tremaining: 24.5s\n",
      "356:\tlearn: 0.2002249\ttotal: 21.2s\tremaining: 24.4s\n",
      "357:\tlearn: 0.1999912\ttotal: 21.2s\tremaining: 24.4s\n",
      "358:\tlearn: 0.1994740\ttotal: 21.3s\tremaining: 24.3s\n",
      "359:\tlearn: 0.1991847\ttotal: 21.3s\tremaining: 24.2s\n",
      "360:\tlearn: 0.1983433\ttotal: 21.4s\tremaining: 24.2s\n",
      "361:\tlearn: 0.1979921\ttotal: 21.4s\tremaining: 24.1s\n",
      "362:\tlearn: 0.1974753\ttotal: 21.5s\tremaining: 24s\n",
      "363:\tlearn: 0.1969329\ttotal: 21.5s\tremaining: 23.9s\n",
      "364:\tlearn: 0.1965358\ttotal: 21.6s\tremaining: 23.9s\n",
      "365:\tlearn: 0.1957367\ttotal: 21.6s\tremaining: 23.8s\n",
      "366:\tlearn: 0.1955666\ttotal: 21.7s\tremaining: 23.8s\n",
      "367:\tlearn: 0.1951651\ttotal: 21.7s\tremaining: 23.7s\n",
      "368:\tlearn: 0.1945123\ttotal: 21.8s\tremaining: 23.6s\n",
      "369:\tlearn: 0.1942251\ttotal: 21.8s\tremaining: 23.5s\n",
      "370:\tlearn: 0.1939524\ttotal: 21.9s\tremaining: 23.5s\n",
      "371:\tlearn: 0.1934483\ttotal: 21.9s\tremaining: 23.4s\n",
      "372:\tlearn: 0.1928410\ttotal: 22s\tremaining: 23.3s\n",
      "373:\tlearn: 0.1924647\ttotal: 22s\tremaining: 23.3s\n",
      "374:\tlearn: 0.1923039\ttotal: 22.1s\tremaining: 23.2s\n",
      "375:\tlearn: 0.1918055\ttotal: 22.1s\tremaining: 23.1s\n",
      "376:\tlearn: 0.1909637\ttotal: 22.2s\tremaining: 23.1s\n",
      "377:\tlearn: 0.1905700\ttotal: 22.2s\tremaining: 23s\n",
      "378:\tlearn: 0.1901201\ttotal: 22.3s\tremaining: 22.9s\n",
      "379:\tlearn: 0.1897327\ttotal: 22.3s\tremaining: 22.9s\n",
      "380:\tlearn: 0.1893590\ttotal: 22.4s\tremaining: 22.8s\n",
      "381:\tlearn: 0.1890706\ttotal: 22.4s\tremaining: 22.7s\n",
      "382:\tlearn: 0.1884685\ttotal: 22.5s\tremaining: 22.7s\n",
      "383:\tlearn: 0.1881833\ttotal: 22.5s\tremaining: 22.6s\n",
      "384:\tlearn: 0.1876263\ttotal: 22.6s\tremaining: 22.5s\n",
      "385:\tlearn: 0.1872223\ttotal: 22.6s\tremaining: 22.5s\n",
      "386:\tlearn: 0.1868090\ttotal: 22.7s\tremaining: 22.4s\n",
      "387:\tlearn: 0.1864621\ttotal: 22.7s\tremaining: 22.3s\n",
      "388:\tlearn: 0.1861472\ttotal: 22.8s\tremaining: 22.3s\n",
      "389:\tlearn: 0.1856544\ttotal: 22.8s\tremaining: 22.2s\n",
      "390:\tlearn: 0.1851141\ttotal: 22.9s\tremaining: 22.1s\n",
      "391:\tlearn: 0.1847043\ttotal: 22.9s\tremaining: 22.1s\n",
      "392:\tlearn: 0.1842956\ttotal: 23s\tremaining: 22s\n",
      "393:\tlearn: 0.1839968\ttotal: 23s\tremaining: 21.9s\n",
      "394:\tlearn: 0.1835001\ttotal: 23.1s\tremaining: 21.9s\n",
      "395:\tlearn: 0.1830144\ttotal: 23.1s\tremaining: 21.8s\n",
      "396:\tlearn: 0.1827964\ttotal: 23.2s\tremaining: 21.7s\n",
      "397:\tlearn: 0.1825608\ttotal: 23.2s\tremaining: 21.7s\n",
      "398:\tlearn: 0.1821178\ttotal: 23.3s\tremaining: 21.6s\n",
      "399:\tlearn: 0.1816190\ttotal: 23.3s\tremaining: 21.5s\n",
      "400:\tlearn: 0.1809205\ttotal: 23.4s\tremaining: 21.5s\n",
      "401:\tlearn: 0.1805838\ttotal: 23.4s\tremaining: 21.4s\n",
      "402:\tlearn: 0.1801509\ttotal: 23.5s\tremaining: 21.3s\n",
      "403:\tlearn: 0.1796792\ttotal: 23.5s\tremaining: 21.3s\n",
      "404:\tlearn: 0.1792623\ttotal: 23.6s\tremaining: 21.2s\n",
      "405:\tlearn: 0.1787603\ttotal: 23.6s\tremaining: 21.1s\n",
      "406:\tlearn: 0.1783319\ttotal: 23.7s\tremaining: 21.1s\n",
      "407:\tlearn: 0.1779790\ttotal: 23.7s\tremaining: 21s\n",
      "408:\tlearn: 0.1776676\ttotal: 23.8s\tremaining: 20.9s\n",
      "409:\tlearn: 0.1773114\ttotal: 23.8s\tremaining: 20.9s\n",
      "410:\tlearn: 0.1769776\ttotal: 23.9s\tremaining: 20.8s\n",
      "411:\tlearn: 0.1765372\ttotal: 23.9s\tremaining: 20.7s\n",
      "412:\tlearn: 0.1759814\ttotal: 24s\tremaining: 20.7s\n",
      "413:\tlearn: 0.1756203\ttotal: 24s\tremaining: 20.6s\n",
      "414:\tlearn: 0.1751826\ttotal: 24.1s\tremaining: 20.5s\n",
      "415:\tlearn: 0.1748657\ttotal: 24.1s\tremaining: 20.5s\n",
      "416:\tlearn: 0.1745581\ttotal: 24.2s\tremaining: 20.4s\n",
      "417:\tlearn: 0.1741584\ttotal: 24.2s\tremaining: 20.4s\n",
      "418:\tlearn: 0.1738388\ttotal: 24.3s\tremaining: 20.3s\n",
      "419:\tlearn: 0.1734446\ttotal: 24.3s\tremaining: 20.2s\n",
      "420:\tlearn: 0.1730151\ttotal: 24.4s\tremaining: 20.1s\n",
      "421:\tlearn: 0.1726414\ttotal: 24.4s\tremaining: 20.1s\n",
      "422:\tlearn: 0.1723102\ttotal: 24.5s\tremaining: 20s\n",
      "423:\tlearn: 0.1719279\ttotal: 24.5s\tremaining: 19.9s\n",
      "424:\tlearn: 0.1716924\ttotal: 24.6s\tremaining: 19.9s\n",
      "425:\tlearn: 0.1711062\ttotal: 24.6s\tremaining: 19.8s\n",
      "426:\tlearn: 0.1708121\ttotal: 24.7s\tremaining: 19.8s\n",
      "427:\tlearn: 0.1704957\ttotal: 24.7s\tremaining: 19.7s\n",
      "428:\tlearn: 0.1702604\ttotal: 24.8s\tremaining: 19.6s\n",
      "429:\tlearn: 0.1699828\ttotal: 24.8s\tremaining: 19.6s\n",
      "430:\tlearn: 0.1697127\ttotal: 24.9s\tremaining: 19.5s\n",
      "431:\tlearn: 0.1691089\ttotal: 24.9s\tremaining: 19.4s\n",
      "432:\tlearn: 0.1686715\ttotal: 25s\tremaining: 19.4s\n",
      "433:\tlearn: 0.1683927\ttotal: 25s\tremaining: 19.3s\n",
      "434:\tlearn: 0.1679845\ttotal: 25.1s\tremaining: 19.2s\n",
      "435:\tlearn: 0.1677090\ttotal: 25.1s\tremaining: 19.2s\n",
      "436:\tlearn: 0.1673433\ttotal: 25.2s\tremaining: 19.1s\n",
      "437:\tlearn: 0.1670408\ttotal: 25.2s\tremaining: 19.1s\n",
      "438:\tlearn: 0.1668400\ttotal: 25.3s\tremaining: 19s\n",
      "439:\tlearn: 0.1664753\ttotal: 25.3s\tremaining: 18.9s\n",
      "440:\tlearn: 0.1661849\ttotal: 25.4s\tremaining: 18.9s\n",
      "441:\tlearn: 0.1658434\ttotal: 25.4s\tremaining: 18.8s\n",
      "442:\tlearn: 0.1654116\ttotal: 25.5s\tremaining: 18.7s\n",
      "443:\tlearn: 0.1651056\ttotal: 25.5s\tremaining: 18.7s\n",
      "444:\tlearn: 0.1647847\ttotal: 25.6s\tremaining: 18.6s\n",
      "445:\tlearn: 0.1644732\ttotal: 25.6s\tremaining: 18.5s\n",
      "446:\tlearn: 0.1641845\ttotal: 25.7s\tremaining: 18.5s\n",
      "447:\tlearn: 0.1636251\ttotal: 25.7s\tremaining: 18.4s\n",
      "448:\tlearn: 0.1633065\ttotal: 25.8s\tremaining: 18.4s\n",
      "449:\tlearn: 0.1628580\ttotal: 25.8s\tremaining: 18.3s\n",
      "450:\tlearn: 0.1625979\ttotal: 25.9s\tremaining: 18.2s\n",
      "451:\tlearn: 0.1621631\ttotal: 25.9s\tremaining: 18.2s\n",
      "452:\tlearn: 0.1618656\ttotal: 26s\tremaining: 18.1s\n",
      "453:\tlearn: 0.1615452\ttotal: 26s\tremaining: 18s\n",
      "454:\tlearn: 0.1611939\ttotal: 26.1s\tremaining: 18s\n",
      "455:\tlearn: 0.1609376\ttotal: 26.1s\tremaining: 17.9s\n",
      "456:\tlearn: 0.1605715\ttotal: 26.2s\tremaining: 17.9s\n",
      "457:\tlearn: 0.1600936\ttotal: 26.2s\tremaining: 17.8s\n",
      "458:\tlearn: 0.1599172\ttotal: 26.3s\tremaining: 17.7s\n",
      "459:\tlearn: 0.1596618\ttotal: 26.3s\tremaining: 17.7s\n",
      "460:\tlearn: 0.1591083\ttotal: 26.4s\tremaining: 17.6s\n",
      "461:\tlearn: 0.1588817\ttotal: 26.4s\tremaining: 17.5s\n",
      "462:\tlearn: 0.1585439\ttotal: 26.4s\tremaining: 17.5s\n",
      "463:\tlearn: 0.1583974\ttotal: 26.5s\tremaining: 17.4s\n",
      "464:\tlearn: 0.1581504\ttotal: 26.6s\tremaining: 17.4s\n",
      "465:\tlearn: 0.1576583\ttotal: 26.6s\tremaining: 17.3s\n",
      "466:\tlearn: 0.1574552\ttotal: 26.7s\tremaining: 17.2s\n",
      "467:\tlearn: 0.1569518\ttotal: 26.7s\tremaining: 17.2s\n",
      "468:\tlearn: 0.1566656\ttotal: 26.8s\tremaining: 17.1s\n",
      "469:\tlearn: 0.1563554\ttotal: 26.8s\tremaining: 17.1s\n",
      "470:\tlearn: 0.1558987\ttotal: 26.9s\tremaining: 17s\n",
      "471:\tlearn: 0.1555481\ttotal: 26.9s\tremaining: 16.9s\n",
      "472:\tlearn: 0.1551849\ttotal: 26.9s\tremaining: 16.9s\n",
      "473:\tlearn: 0.1549112\ttotal: 27s\tremaining: 16.8s\n",
      "474:\tlearn: 0.1546622\ttotal: 27.1s\tremaining: 16.7s\n",
      "475:\tlearn: 0.1544643\ttotal: 27.1s\tremaining: 16.7s\n",
      "476:\tlearn: 0.1541406\ttotal: 27.1s\tremaining: 16.6s\n",
      "477:\tlearn: 0.1538674\ttotal: 27.2s\tremaining: 16.6s\n",
      "478:\tlearn: 0.1536508\ttotal: 27.2s\tremaining: 16.5s\n",
      "479:\tlearn: 0.1532192\ttotal: 27.3s\tremaining: 16.4s\n",
      "480:\tlearn: 0.1529689\ttotal: 27.3s\tremaining: 16.4s\n",
      "481:\tlearn: 0.1527572\ttotal: 27.4s\tremaining: 16.3s\n",
      "482:\tlearn: 0.1525886\ttotal: 27.4s\tremaining: 16.2s\n",
      "483:\tlearn: 0.1523702\ttotal: 27.5s\tremaining: 16.2s\n",
      "484:\tlearn: 0.1520687\ttotal: 27.5s\tremaining: 16.1s\n",
      "485:\tlearn: 0.1518011\ttotal: 27.6s\tremaining: 16.1s\n",
      "486:\tlearn: 0.1515329\ttotal: 27.6s\tremaining: 16s\n",
      "487:\tlearn: 0.1513171\ttotal: 27.7s\tremaining: 15.9s\n",
      "488:\tlearn: 0.1510691\ttotal: 27.7s\tremaining: 15.9s\n",
      "489:\tlearn: 0.1508279\ttotal: 27.8s\tremaining: 15.8s\n",
      "490:\tlearn: 0.1504908\ttotal: 27.8s\tremaining: 15.8s\n",
      "491:\tlearn: 0.1499831\ttotal: 27.9s\tremaining: 15.7s\n",
      "492:\tlearn: 0.1496041\ttotal: 27.9s\tremaining: 15.6s\n",
      "493:\tlearn: 0.1492275\ttotal: 28s\tremaining: 15.6s\n",
      "494:\tlearn: 0.1489526\ttotal: 28s\tremaining: 15.5s\n",
      "495:\tlearn: 0.1486677\ttotal: 28.1s\tremaining: 15.5s\n",
      "496:\tlearn: 0.1482256\ttotal: 28.1s\tremaining: 15.4s\n",
      "497:\tlearn: 0.1479693\ttotal: 28.2s\tremaining: 15.3s\n",
      "498:\tlearn: 0.1476176\ttotal: 28.2s\tremaining: 15.3s\n",
      "499:\tlearn: 0.1472302\ttotal: 28.3s\tremaining: 15.2s\n",
      "500:\tlearn: 0.1469718\ttotal: 28.3s\tremaining: 15.2s\n",
      "501:\tlearn: 0.1468300\ttotal: 28.4s\tremaining: 15.1s\n",
      "502:\tlearn: 0.1466126\ttotal: 28.4s\tremaining: 15s\n",
      "503:\tlearn: 0.1462653\ttotal: 28.5s\tremaining: 15s\n",
      "504:\tlearn: 0.1459975\ttotal: 28.5s\tremaining: 14.9s\n",
      "505:\tlearn: 0.1457113\ttotal: 28.6s\tremaining: 14.8s\n",
      "506:\tlearn: 0.1455214\ttotal: 28.6s\tremaining: 14.8s\n",
      "507:\tlearn: 0.1451754\ttotal: 28.7s\tremaining: 14.7s\n",
      "508:\tlearn: 0.1449580\ttotal: 28.7s\tremaining: 14.7s\n",
      "509:\tlearn: 0.1448719\ttotal: 28.8s\tremaining: 14.6s\n",
      "510:\tlearn: 0.1446166\ttotal: 28.8s\tremaining: 14.6s\n",
      "511:\tlearn: 0.1442966\ttotal: 28.9s\tremaining: 14.5s\n",
      "512:\tlearn: 0.1439339\ttotal: 28.9s\tremaining: 14.4s\n",
      "513:\tlearn: 0.1436830\ttotal: 29s\tremaining: 14.4s\n",
      "514:\tlearn: 0.1433897\ttotal: 29s\tremaining: 14.3s\n",
      "515:\tlearn: 0.1430562\ttotal: 29.1s\tremaining: 14.3s\n",
      "516:\tlearn: 0.1428577\ttotal: 29.1s\tremaining: 14.2s\n",
      "517:\tlearn: 0.1425510\ttotal: 29.2s\tremaining: 14.1s\n",
      "518:\tlearn: 0.1422910\ttotal: 29.2s\tremaining: 14.1s\n",
      "519:\tlearn: 0.1420408\ttotal: 29.3s\tremaining: 14s\n",
      "520:\tlearn: 0.1416600\ttotal: 29.3s\tremaining: 14s\n",
      "521:\tlearn: 0.1413359\ttotal: 29.4s\tremaining: 13.9s\n",
      "522:\tlearn: 0.1411526\ttotal: 29.4s\tremaining: 13.8s\n",
      "523:\tlearn: 0.1409593\ttotal: 29.5s\tremaining: 13.8s\n",
      "524:\tlearn: 0.1405022\ttotal: 29.5s\tremaining: 13.7s\n",
      "525:\tlearn: 0.1401757\ttotal: 29.6s\tremaining: 13.7s\n",
      "526:\tlearn: 0.1398108\ttotal: 29.6s\tremaining: 13.6s\n",
      "527:\tlearn: 0.1394356\ttotal: 29.7s\tremaining: 13.5s\n",
      "528:\tlearn: 0.1389913\ttotal: 29.7s\tremaining: 13.5s\n",
      "529:\tlearn: 0.1386836\ttotal: 29.8s\tremaining: 13.4s\n",
      "530:\tlearn: 0.1384499\ttotal: 29.8s\tremaining: 13.4s\n",
      "531:\tlearn: 0.1381469\ttotal: 29.9s\tremaining: 13.3s\n",
      "532:\tlearn: 0.1378604\ttotal: 29.9s\tremaining: 13.3s\n",
      "533:\tlearn: 0.1376636\ttotal: 30s\tremaining: 13.2s\n",
      "534:\tlearn: 0.1374919\ttotal: 30s\tremaining: 13.1s\n",
      "535:\tlearn: 0.1372304\ttotal: 30.1s\tremaining: 13.1s\n",
      "536:\tlearn: 0.1370689\ttotal: 30.1s\tremaining: 13s\n",
      "537:\tlearn: 0.1367167\ttotal: 30.2s\tremaining: 13s\n",
      "538:\tlearn: 0.1364685\ttotal: 30.2s\tremaining: 12.9s\n",
      "539:\tlearn: 0.1362702\ttotal: 30.3s\tremaining: 12.8s\n",
      "540:\tlearn: 0.1359864\ttotal: 30.3s\tremaining: 12.8s\n",
      "541:\tlearn: 0.1357632\ttotal: 30.4s\tremaining: 12.7s\n",
      "542:\tlearn: 0.1355742\ttotal: 30.4s\tremaining: 12.7s\n",
      "543:\tlearn: 0.1353411\ttotal: 30.4s\tremaining: 12.6s\n",
      "544:\tlearn: 0.1351512\ttotal: 30.5s\tremaining: 12.5s\n",
      "545:\tlearn: 0.1348928\ttotal: 30.5s\tremaining: 12.5s\n",
      "546:\tlearn: 0.1347987\ttotal: 30.6s\tremaining: 12.4s\n",
      "547:\tlearn: 0.1344476\ttotal: 30.6s\tremaining: 12.4s\n",
      "548:\tlearn: 0.1341563\ttotal: 30.7s\tremaining: 12.3s\n",
      "549:\tlearn: 0.1338388\ttotal: 30.7s\tremaining: 12.2s\n",
      "550:\tlearn: 0.1335546\ttotal: 30.8s\tremaining: 12.2s\n",
      "551:\tlearn: 0.1330612\ttotal: 30.8s\tremaining: 12.1s\n",
      "552:\tlearn: 0.1328255\ttotal: 30.9s\tremaining: 12.1s\n",
      "553:\tlearn: 0.1326139\ttotal: 31s\tremaining: 12s\n",
      "554:\tlearn: 0.1324102\ttotal: 31s\tremaining: 12s\n",
      "555:\tlearn: 0.1321695\ttotal: 31.1s\tremaining: 11.9s\n",
      "556:\tlearn: 0.1319257\ttotal: 31.2s\tremaining: 11.9s\n",
      "557:\tlearn: 0.1316951\ttotal: 31.3s\tremaining: 11.8s\n",
      "558:\tlearn: 0.1314445\ttotal: 31.3s\tremaining: 11.8s\n",
      "559:\tlearn: 0.1311767\ttotal: 31.4s\tremaining: 11.7s\n",
      "560:\tlearn: 0.1309772\ttotal: 31.5s\tremaining: 11.7s\n",
      "561:\tlearn: 0.1308246\ttotal: 31.6s\tremaining: 11.6s\n",
      "562:\tlearn: 0.1306615\ttotal: 31.7s\tremaining: 11.6s\n",
      "563:\tlearn: 0.1304271\ttotal: 31.8s\tremaining: 11.6s\n",
      "564:\tlearn: 0.1302287\ttotal: 31.9s\tremaining: 11.5s\n",
      "565:\tlearn: 0.1300845\ttotal: 32s\tremaining: 11.5s\n",
      "566:\tlearn: 0.1298126\ttotal: 32.1s\tremaining: 11.4s\n",
      "567:\tlearn: 0.1295287\ttotal: 32.2s\tremaining: 11.4s\n",
      "568:\tlearn: 0.1292858\ttotal: 32.2s\tremaining: 11.3s\n",
      "569:\tlearn: 0.1290163\ttotal: 32.3s\tremaining: 11.3s\n",
      "570:\tlearn: 0.1288647\ttotal: 32.4s\tremaining: 11.2s\n",
      "571:\tlearn: 0.1285738\ttotal: 32.5s\tremaining: 11.2s\n",
      "572:\tlearn: 0.1283346\ttotal: 32.6s\tremaining: 11.2s\n",
      "573:\tlearn: 0.1281271\ttotal: 32.7s\tremaining: 11.1s\n",
      "574:\tlearn: 0.1279429\ttotal: 32.8s\tremaining: 11.1s\n",
      "575:\tlearn: 0.1275771\ttotal: 32.9s\tremaining: 11s\n",
      "576:\tlearn: 0.1273983\ttotal: 33s\tremaining: 11s\n",
      "577:\tlearn: 0.1272694\ttotal: 33.1s\tremaining: 10.9s\n",
      "578:\tlearn: 0.1270544\ttotal: 33.2s\tremaining: 10.9s\n",
      "579:\tlearn: 0.1268714\ttotal: 33.3s\tremaining: 10.8s\n",
      "580:\tlearn: 0.1266432\ttotal: 33.4s\tremaining: 10.8s\n",
      "581:\tlearn: 0.1263898\ttotal: 33.4s\tremaining: 10.7s\n",
      "582:\tlearn: 0.1262445\ttotal: 33.5s\tremaining: 10.7s\n",
      "583:\tlearn: 0.1260182\ttotal: 33.6s\tremaining: 10.7s\n",
      "584:\tlearn: 0.1258259\ttotal: 33.7s\tremaining: 10.6s\n",
      "585:\tlearn: 0.1257432\ttotal: 33.8s\tremaining: 10.6s\n",
      "586:\tlearn: 0.1255448\ttotal: 33.9s\tremaining: 10.5s\n",
      "587:\tlearn: 0.1253595\ttotal: 34s\tremaining: 10.5s\n",
      "588:\tlearn: 0.1250792\ttotal: 34.1s\tremaining: 10.4s\n",
      "589:\tlearn: 0.1248502\ttotal: 34.2s\tremaining: 10.4s\n",
      "590:\tlearn: 0.1246900\ttotal: 34.2s\tremaining: 10.3s\n",
      "591:\tlearn: 0.1243860\ttotal: 34.3s\tremaining: 10.3s\n",
      "592:\tlearn: 0.1242368\ttotal: 34.4s\tremaining: 10.2s\n",
      "593:\tlearn: 0.1240370\ttotal: 34.5s\tremaining: 10.2s\n",
      "594:\tlearn: 0.1237911\ttotal: 34.6s\tremaining: 10.1s\n",
      "595:\tlearn: 0.1234281\ttotal: 34.6s\tremaining: 10.1s\n",
      "596:\tlearn: 0.1233205\ttotal: 34.7s\tremaining: 9.99s\n",
      "597:\tlearn: 0.1230215\ttotal: 34.7s\tremaining: 9.93s\n",
      "598:\tlearn: 0.1226925\ttotal: 34.8s\tremaining: 9.87s\n",
      "599:\tlearn: 0.1223933\ttotal: 34.8s\tremaining: 9.81s\n",
      "600:\tlearn: 0.1220304\ttotal: 34.9s\tremaining: 9.75s\n",
      "601:\tlearn: 0.1218752\ttotal: 34.9s\tremaining: 9.69s\n",
      "602:\tlearn: 0.1216559\ttotal: 35s\tremaining: 9.63s\n",
      "603:\tlearn: 0.1214351\ttotal: 35s\tremaining: 9.57s\n",
      "604:\tlearn: 0.1213317\ttotal: 35.1s\tremaining: 9.51s\n",
      "605:\tlearn: 0.1208986\ttotal: 35.1s\tremaining: 9.45s\n",
      "606:\tlearn: 0.1207568\ttotal: 35.2s\tremaining: 9.39s\n",
      "607:\tlearn: 0.1205694\ttotal: 35.2s\tremaining: 9.33s\n",
      "608:\tlearn: 0.1203479\ttotal: 35.3s\tremaining: 9.27s\n",
      "609:\tlearn: 0.1202158\ttotal: 35.3s\tremaining: 9.21s\n",
      "610:\tlearn: 0.1198758\ttotal: 35.4s\tremaining: 9.15s\n",
      "611:\tlearn: 0.1197272\ttotal: 35.4s\tremaining: 9.09s\n",
      "612:\tlearn: 0.1194652\ttotal: 35.5s\tremaining: 9.03s\n",
      "613:\tlearn: 0.1193931\ttotal: 35.5s\tremaining: 8.97s\n",
      "614:\tlearn: 0.1191698\ttotal: 35.6s\tremaining: 8.91s\n",
      "615:\tlearn: 0.1190094\ttotal: 35.6s\tremaining: 8.85s\n",
      "616:\tlearn: 0.1187438\ttotal: 35.7s\tremaining: 8.79s\n",
      "617:\tlearn: 0.1186258\ttotal: 35.7s\tremaining: 8.73s\n",
      "618:\tlearn: 0.1184001\ttotal: 35.8s\tremaining: 8.67s\n",
      "619:\tlearn: 0.1182593\ttotal: 35.8s\tremaining: 8.61s\n",
      "620:\tlearn: 0.1180473\ttotal: 35.9s\tremaining: 8.54s\n",
      "621:\tlearn: 0.1178882\ttotal: 35.9s\tremaining: 8.49s\n",
      "622:\tlearn: 0.1176997\ttotal: 36s\tremaining: 8.43s\n",
      "623:\tlearn: 0.1174832\ttotal: 36s\tremaining: 8.37s\n",
      "624:\tlearn: 0.1173104\ttotal: 36.1s\tremaining: 8.31s\n",
      "625:\tlearn: 0.1170675\ttotal: 36.1s\tremaining: 8.25s\n",
      "626:\tlearn: 0.1167625\ttotal: 36.2s\tremaining: 8.19s\n",
      "627:\tlearn: 0.1165977\ttotal: 36.2s\tremaining: 8.13s\n",
      "628:\tlearn: 0.1163848\ttotal: 36.3s\tremaining: 8.07s\n",
      "629:\tlearn: 0.1161678\ttotal: 36.3s\tremaining: 8.01s\n",
      "630:\tlearn: 0.1158676\ttotal: 36.4s\tremaining: 7.95s\n",
      "631:\tlearn: 0.1156325\ttotal: 36.4s\tremaining: 7.89s\n",
      "632:\tlearn: 0.1154645\ttotal: 36.5s\tremaining: 7.83s\n",
      "633:\tlearn: 0.1151604\ttotal: 36.5s\tremaining: 7.77s\n",
      "634:\tlearn: 0.1149111\ttotal: 36.5s\tremaining: 7.71s\n",
      "635:\tlearn: 0.1148060\ttotal: 36.6s\tremaining: 7.65s\n",
      "636:\tlearn: 0.1146353\ttotal: 36.6s\tremaining: 7.59s\n",
      "637:\tlearn: 0.1145339\ttotal: 36.7s\tremaining: 7.53s\n",
      "638:\tlearn: 0.1143779\ttotal: 36.7s\tremaining: 7.47s\n",
      "639:\tlearn: 0.1142184\ttotal: 36.8s\tremaining: 7.41s\n",
      "640:\tlearn: 0.1140631\ttotal: 36.8s\tremaining: 7.36s\n",
      "641:\tlearn: 0.1138254\ttotal: 36.9s\tremaining: 7.3s\n",
      "642:\tlearn: 0.1137122\ttotal: 36.9s\tremaining: 7.24s\n",
      "643:\tlearn: 0.1134628\ttotal: 37s\tremaining: 7.18s\n",
      "644:\tlearn: 0.1132715\ttotal: 37s\tremaining: 7.12s\n",
      "645:\tlearn: 0.1130705\ttotal: 37.1s\tremaining: 7.06s\n",
      "646:\tlearn: 0.1127763\ttotal: 37.1s\tremaining: 7s\n",
      "647:\tlearn: 0.1126208\ttotal: 37.2s\tremaining: 6.94s\n",
      "648:\tlearn: 0.1124727\ttotal: 37.2s\tremaining: 6.88s\n",
      "649:\tlearn: 0.1123777\ttotal: 37.3s\tremaining: 6.83s\n",
      "650:\tlearn: 0.1122021\ttotal: 37.3s\tremaining: 6.76s\n",
      "651:\tlearn: 0.1120388\ttotal: 37.4s\tremaining: 6.71s\n",
      "652:\tlearn: 0.1118088\ttotal: 37.4s\tremaining: 6.65s\n",
      "653:\tlearn: 0.1115802\ttotal: 37.5s\tremaining: 6.59s\n",
      "654:\tlearn: 0.1113937\ttotal: 37.5s\tremaining: 6.53s\n",
      "655:\tlearn: 0.1111582\ttotal: 37.6s\tremaining: 6.47s\n",
      "656:\tlearn: 0.1109698\ttotal: 37.6s\tremaining: 6.41s\n",
      "657:\tlearn: 0.1107701\ttotal: 37.7s\tremaining: 6.35s\n",
      "658:\tlearn: 0.1105103\ttotal: 37.7s\tremaining: 6.29s\n",
      "659:\tlearn: 0.1102487\ttotal: 37.8s\tremaining: 6.24s\n",
      "660:\tlearn: 0.1100959\ttotal: 37.8s\tremaining: 6.18s\n",
      "661:\tlearn: 0.1099491\ttotal: 37.9s\tremaining: 6.12s\n",
      "662:\tlearn: 0.1097816\ttotal: 37.9s\tremaining: 6.06s\n",
      "663:\tlearn: 0.1095488\ttotal: 38s\tremaining: 6s\n",
      "664:\tlearn: 0.1094258\ttotal: 38s\tremaining: 5.95s\n",
      "665:\tlearn: 0.1093146\ttotal: 38.1s\tremaining: 5.89s\n",
      "666:\tlearn: 0.1090688\ttotal: 38.1s\tremaining: 5.83s\n",
      "667:\tlearn: 0.1089713\ttotal: 38.2s\tremaining: 5.77s\n",
      "668:\tlearn: 0.1088394\ttotal: 38.2s\tremaining: 5.71s\n",
      "669:\tlearn: 0.1086886\ttotal: 38.3s\tremaining: 5.66s\n",
      "670:\tlearn: 0.1084649\ttotal: 38.3s\tremaining: 5.6s\n",
      "671:\tlearn: 0.1083894\ttotal: 38.4s\tremaining: 5.54s\n",
      "672:\tlearn: 0.1081579\ttotal: 38.4s\tremaining: 5.48s\n",
      "673:\tlearn: 0.1079100\ttotal: 38.5s\tremaining: 5.42s\n",
      "674:\tlearn: 0.1077187\ttotal: 38.5s\tremaining: 5.36s\n",
      "675:\tlearn: 0.1074027\ttotal: 38.6s\tremaining: 5.3s\n",
      "676:\tlearn: 0.1071805\ttotal: 38.6s\tremaining: 5.25s\n",
      "677:\tlearn: 0.1069663\ttotal: 38.7s\tremaining: 5.19s\n",
      "678:\tlearn: 0.1067997\ttotal: 38.7s\tremaining: 5.13s\n",
      "679:\tlearn: 0.1066596\ttotal: 38.8s\tremaining: 5.07s\n",
      "680:\tlearn: 0.1064385\ttotal: 38.8s\tremaining: 5.01s\n",
      "681:\tlearn: 0.1063737\ttotal: 38.9s\tremaining: 4.96s\n",
      "682:\tlearn: 0.1061961\ttotal: 38.9s\tremaining: 4.9s\n",
      "683:\tlearn: 0.1059813\ttotal: 39s\tremaining: 4.84s\n",
      "684:\tlearn: 0.1058097\ttotal: 39s\tremaining: 4.79s\n",
      "685:\tlearn: 0.1056361\ttotal: 39.1s\tremaining: 4.73s\n",
      "686:\tlearn: 0.1054735\ttotal: 39.1s\tremaining: 4.67s\n",
      "687:\tlearn: 0.1053913\ttotal: 39.2s\tremaining: 4.61s\n",
      "688:\tlearn: 0.1052401\ttotal: 39.2s\tremaining: 4.55s\n",
      "689:\tlearn: 0.1049392\ttotal: 39.3s\tremaining: 4.49s\n",
      "690:\tlearn: 0.1047398\ttotal: 39.3s\tremaining: 4.44s\n",
      "691:\tlearn: 0.1046614\ttotal: 39.4s\tremaining: 4.38s\n",
      "692:\tlearn: 0.1045088\ttotal: 39.4s\tremaining: 4.32s\n",
      "693:\tlearn: 0.1043123\ttotal: 39.4s\tremaining: 4.26s\n",
      "694:\tlearn: 0.1040871\ttotal: 39.5s\tremaining: 4.21s\n",
      "695:\tlearn: 0.1038000\ttotal: 39.5s\tremaining: 4.15s\n",
      "696:\tlearn: 0.1035906\ttotal: 39.6s\tremaining: 4.09s\n",
      "697:\tlearn: 0.1034208\ttotal: 39.6s\tremaining: 4.03s\n",
      "698:\tlearn: 0.1031683\ttotal: 39.7s\tremaining: 3.97s\n",
      "699:\tlearn: 0.1030051\ttotal: 39.7s\tremaining: 3.92s\n",
      "700:\tlearn: 0.1027412\ttotal: 39.8s\tremaining: 3.86s\n",
      "701:\tlearn: 0.1026468\ttotal: 39.8s\tremaining: 3.8s\n",
      "702:\tlearn: 0.1025682\ttotal: 39.9s\tremaining: 3.74s\n",
      "703:\tlearn: 0.1023955\ttotal: 39.9s\tremaining: 3.69s\n",
      "704:\tlearn: 0.1022643\ttotal: 40s\tremaining: 3.63s\n",
      "705:\tlearn: 0.1021421\ttotal: 40s\tremaining: 3.57s\n",
      "706:\tlearn: 0.1019782\ttotal: 40.1s\tremaining: 3.52s\n",
      "707:\tlearn: 0.1018689\ttotal: 40.1s\tremaining: 3.46s\n",
      "708:\tlearn: 0.1017250\ttotal: 40.2s\tremaining: 3.4s\n",
      "709:\tlearn: 0.1015787\ttotal: 40.2s\tremaining: 3.34s\n",
      "710:\tlearn: 0.1013976\ttotal: 40.3s\tremaining: 3.29s\n",
      "711:\tlearn: 0.1011751\ttotal: 40.3s\tremaining: 3.23s\n",
      "712:\tlearn: 0.1008885\ttotal: 40.4s\tremaining: 3.17s\n",
      "713:\tlearn: 0.1007117\ttotal: 40.4s\tremaining: 3.11s\n",
      "714:\tlearn: 0.1006571\ttotal: 40.5s\tremaining: 3.06s\n",
      "715:\tlearn: 0.1004643\ttotal: 40.5s\tremaining: 3s\n",
      "716:\tlearn: 0.1003113\ttotal: 40.6s\tremaining: 2.94s\n",
      "717:\tlearn: 0.1001527\ttotal: 40.6s\tremaining: 2.88s\n",
      "718:\tlearn: 0.0998873\ttotal: 40.7s\tremaining: 2.83s\n",
      "719:\tlearn: 0.0997649\ttotal: 40.7s\tremaining: 2.77s\n",
      "720:\tlearn: 0.0996523\ttotal: 40.8s\tremaining: 2.71s\n",
      "721:\tlearn: 0.0994268\ttotal: 40.8s\tremaining: 2.66s\n",
      "722:\tlearn: 0.0991498\ttotal: 40.8s\tremaining: 2.6s\n",
      "723:\tlearn: 0.0990028\ttotal: 40.9s\tremaining: 2.54s\n",
      "724:\tlearn: 0.0988976\ttotal: 40.9s\tremaining: 2.48s\n",
      "725:\tlearn: 0.0988495\ttotal: 41s\tremaining: 2.43s\n",
      "726:\tlearn: 0.0986765\ttotal: 41s\tremaining: 2.37s\n",
      "727:\tlearn: 0.0985755\ttotal: 41.1s\tremaining: 2.31s\n",
      "728:\tlearn: 0.0984626\ttotal: 41.1s\tremaining: 2.26s\n",
      "729:\tlearn: 0.0983276\ttotal: 41.2s\tremaining: 2.2s\n",
      "730:\tlearn: 0.0981637\ttotal: 41.2s\tremaining: 2.14s\n",
      "731:\tlearn: 0.0979761\ttotal: 41.3s\tremaining: 2.09s\n",
      "732:\tlearn: 0.0978535\ttotal: 41.3s\tremaining: 2.03s\n",
      "733:\tlearn: 0.0976165\ttotal: 41.4s\tremaining: 1.97s\n",
      "734:\tlearn: 0.0974359\ttotal: 41.4s\tremaining: 1.92s\n",
      "735:\tlearn: 0.0971963\ttotal: 41.5s\tremaining: 1.86s\n",
      "736:\tlearn: 0.0971154\ttotal: 41.5s\tremaining: 1.8s\n",
      "737:\tlearn: 0.0969327\ttotal: 41.6s\tremaining: 1.75s\n",
      "738:\tlearn: 0.0967147\ttotal: 41.6s\tremaining: 1.69s\n",
      "739:\tlearn: 0.0965857\ttotal: 41.7s\tremaining: 1.63s\n",
      "740:\tlearn: 0.0964189\ttotal: 41.7s\tremaining: 1.58s\n",
      "741:\tlearn: 0.0962840\ttotal: 41.8s\tremaining: 1.52s\n",
      "742:\tlearn: 0.0960606\ttotal: 41.8s\tremaining: 1.46s\n",
      "743:\tlearn: 0.0959347\ttotal: 41.9s\tremaining: 1.41s\n",
      "744:\tlearn: 0.0958026\ttotal: 41.9s\tremaining: 1.35s\n",
      "745:\tlearn: 0.0956991\ttotal: 42s\tremaining: 1.29s\n",
      "746:\tlearn: 0.0955439\ttotal: 42s\tremaining: 1.24s\n",
      "747:\tlearn: 0.0953264\ttotal: 42.1s\tremaining: 1.18s\n",
      "748:\tlearn: 0.0951708\ttotal: 42.1s\tremaining: 1.12s\n",
      "749:\tlearn: 0.0950410\ttotal: 42.2s\tremaining: 1.07s\n",
      "750:\tlearn: 0.0948920\ttotal: 42.2s\tremaining: 1.01s\n",
      "751:\tlearn: 0.0947495\ttotal: 42.3s\tremaining: 955ms\n",
      "752:\tlearn: 0.0946485\ttotal: 42.3s\tremaining: 899ms\n",
      "753:\tlearn: 0.0944556\ttotal: 42.4s\tremaining: 843ms\n",
      "754:\tlearn: 0.0942670\ttotal: 42.4s\tremaining: 786ms\n",
      "755:\tlearn: 0.0940631\ttotal: 42.4s\tremaining: 730ms\n",
      "756:\tlearn: 0.0939068\ttotal: 42.5s\tremaining: 674ms\n",
      "757:\tlearn: 0.0937287\ttotal: 42.5s\tremaining: 617ms\n",
      "758:\tlearn: 0.0936149\ttotal: 42.6s\tremaining: 561ms\n",
      "759:\tlearn: 0.0934863\ttotal: 42.6s\tremaining: 505ms\n",
      "760:\tlearn: 0.0933495\ttotal: 42.7s\tremaining: 449ms\n",
      "761:\tlearn: 0.0932195\ttotal: 42.7s\tremaining: 393ms\n",
      "762:\tlearn: 0.0930405\ttotal: 42.8s\tremaining: 336ms\n",
      "763:\tlearn: 0.0929307\ttotal: 42.8s\tremaining: 280ms\n",
      "764:\tlearn: 0.0927088\ttotal: 42.9s\tremaining: 224ms\n",
      "765:\tlearn: 0.0924879\ttotal: 42.9s\tremaining: 168ms\n",
      "766:\tlearn: 0.0923636\ttotal: 43s\tremaining: 112ms\n",
      "767:\tlearn: 0.0922112\ttotal: 43s\tremaining: 56ms\n",
      "768:\tlearn: 0.0920422\ttotal: 43.1s\tremaining: 0us\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86      4206\n",
      "           1       0.00      0.00      0.00      1410\n",
      "\n",
      "    accuracy                           0.75      5616\n",
      "   macro avg       0.37      0.50      0.43      5616\n",
      "weighted avg       0.56      0.75      0.64      5616\n",
      "\n",
      "RandomForest Precision: 0.0\n",
      "RandomForest Recall: 0.0\n",
      "RandomForest F1 Score: 0.0\n",
      "RandomForest Next Candle Prediction: 0\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "LGBM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83      4206\n",
      "           1       0.42      0.20      0.28      1410\n",
      "\n",
      "    accuracy                           0.73      5616\n",
      "   macro avg       0.60      0.55      0.55      5616\n",
      "weighted avg       0.68      0.73      0.69      5616\n",
      "\n",
      "LGBM Precision: 0.41884057971014493\n",
      "LGBM Recall: 0.2049645390070922\n",
      "LGBM F1 Score: 0.2752380952380952\n",
      "LGBM Next Candle Prediction: 0\n",
      "\n",
      "CatBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.83      4206\n",
      "           1       0.41      0.22      0.29      1410\n",
      "\n",
      "    accuracy                           0.72      5616\n",
      "   macro avg       0.59      0.56      0.56      5616\n",
      "weighted avg       0.68      0.72      0.69      5616\n",
      "\n",
      "CatBoost Precision: 0.41009055627425617\n",
      "CatBoost Recall: 0.22482269503546098\n",
      "CatBoost F1 Score: 0.2904260192395786\n",
      "CatBoost Next Candle Prediction: 0\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8810557608826248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8810557608826248\n",
      "For PGSUS.IS, the best model is LGBM with F1 score 0.3333333333333333 and Next Candlestick Pattern 1\n",
      "For NUGYO.IS, the best model is CatBoost with F1 score 0.2564102564102564 and Next Candlestick Pattern 1\n",
      "For KARSN.IS, the best model is CatBoost with F1 score 0.23312883435582826 and Next Candlestick Pattern 1\n",
      "For LOGO.IS, the best model is CatBoost with F1 score 0.19047619047619047 and Next Candlestick Pattern 1\n",
      "For KARTN.IS, the best model is LGBM with F1 score 0.16793893129770993 and Next Candlestick Pattern 1\n",
      "For GESAN.IS, the best model is CatBoost with F1 score 0.15942028985507248 and Next Candlestick Pattern 1\n",
      "For ISFIN.IS, the best model is CatBoost with F1 score 0.13138686131386862 and Next Candlestick Pattern 1\n",
      "For TSPOR.IS, the best model is CatBoost with F1 score 0.12903225806451613 and Next Candlestick Pattern 1\n",
      "For CEMTS.IS, the best model is LGBM with F1 score 0.12598425196850394 and Next Candlestick Pattern 1\n",
      "For PRKAB.IS, the best model is CatBoost with F1 score 0.12413793103448276 and Next Candlestick Pattern 1\n",
      "For SASA.IS, the best model is CatBoost with F1 score 0.11851851851851851 and Next Candlestick Pattern 1\n",
      "For YYLGD.IS, the best model is LGBM with F1 score 0.1167883211678832 and Next Candlestick Pattern 1\n",
      "For KRDMD.IS, the best model is LGBM with F1 score 0.11510791366906475 and Next Candlestick Pattern 1\n",
      "For TUPRS.IS, the best model is CatBoost with F1 score 0.11347517730496455 and Next Candlestick Pattern 1\n",
      "For TUKAS.IS, the best model is CatBoost with F1 score 0.1103448275862069 and Next Candlestick Pattern 1\n",
      "For SNGYO.IS, the best model is LGBM with F1 score 0.1081081081081081 and Next Candlestick Pattern 1\n",
      "For ALARK.IS, the best model is CatBoost with F1 score 0.09375 and Next Candlestick Pattern 1\n",
      "For JANTS.IS, the best model is CatBoost with F1 score 0.0923076923076923 and Next Candlestick Pattern 1\n",
      "For DEVA.IS, the best model is LGBM with F1 score 0.0916030534351145 and Next Candlestick Pattern 1\n",
      "For CCOLA.IS, the best model is LGBM with F1 score 0.09022556390977443 and Next Candlestick Pattern 1\n",
      "For TSKB.IS, the best model is CatBoost with F1 score 0.08955223880597016 and Next Candlestick Pattern 1\n",
      "For AKSA.IS, the best model is CatBoost with F1 score 0.08547008547008547 and Next Candlestick Pattern 1\n",
      "For ECILC.IS, the best model is CatBoost with F1 score 0.08547008547008547 and Next Candlestick Pattern 1\n",
      "For OYAKC.IS, the best model is LGBM with F1 score 0.08333333333333333 and Next Candlestick Pattern 1\n",
      "For ULKER.IS, the best model is CatBoost with F1 score 0.07936507936507937 and Next Candlestick Pattern 1\n",
      "For THYAO.IS, the best model is CatBoost with F1 score 0.07874015748031495 and Next Candlestick Pattern 1\n",
      "For GARAN.IS, the best model is CatBoost with F1 score 0.07575757575757576 and Next Candlestick Pattern 1\n",
      "For GWIND.IS, the best model is CatBoost with F1 score 0.07462686567164178 and Next Candlestick Pattern 1\n",
      "For SAHOL.IS, the best model is LGBM with F1 score 0.07017543859649122 and Next Candlestick Pattern 1\n",
      "For AKBNK.IS, the best model is LGBM with F1 score 0.06956521739130433 and Next Candlestick Pattern 1\n",
      "For AKSEN.IS, the best model is CatBoost with F1 score 0.06837606837606838 and Next Candlestick Pattern 1\n",
      "For TKFEN.IS, the best model is CatBoost with F1 score 0.06802721088435373 and Next Candlestick Pattern 1\n",
      "For ISMEN.IS, the best model is CatBoost with F1 score 0.06451612903225806 and Next Candlestick Pattern 1\n",
      "For AKFGY.IS, the best model is LGBM with F1 score 0.06349206349206349 and Next Candlestick Pattern 1\n",
      "For DOAS.IS, the best model is CatBoost with F1 score 0.0625 and Next Candlestick Pattern 1\n",
      "For GLYHO.IS, the best model is CatBoost with F1 score 0.06153846153846155 and Next Candlestick Pattern 1\n",
      "For TTKOM.IS, the best model is LGBM with F1 score 0.060606060606060615 and Next Candlestick Pattern 1\n",
      "For MGROS.IS, the best model is CatBoost with F1 score 0.05970149253731343 and Next Candlestick Pattern 0\n",
      "For CIMSA.IS, the best model is CatBoost with F1 score 0.0588235294117647 and Next Candlestick Pattern 1\n",
      "For YATAS.IS, the best model is CatBoost with F1 score 0.05797101449275363 and Next Candlestick Pattern 1\n",
      "For VESTL.IS, the best model is LGBM with F1 score 0.05714285714285715 and Next Candlestick Pattern 0\n",
      "For TMSN.IS, the best model is CatBoost with F1 score 0.055944055944055944 and Next Candlestick Pattern 1\n",
      "For ISGYO.IS, the best model is LGBM with F1 score 0.049180327868852465 and Next Candlestick Pattern 1\n",
      "For ISCTR.IS, the best model is CatBoost with F1 score 0.047999999999999994 and Next Candlestick Pattern 1\n",
      "For TCELL.IS, the best model is CatBoost with F1 score 0.04580152671755725 and Next Candlestick Pattern 1\n",
      "For BAGFS.IS, the best model is CatBoost with F1 score 0.045454545454545456 and Next Candlestick Pattern 1\n",
      "For KONTR.IS, the best model is LGBM with F1 score 0.045454545454545456 and Next Candlestick Pattern 1\n",
      "For YKBNK.IS, the best model is CatBoost with F1 score 0.045112781954887216 and Next Candlestick Pattern 0\n",
      "For GOZDE.IS, the best model is LGBM with F1 score 0.0437956204379562 and Next Candlestick Pattern 1\n",
      "For AGHOL.IS, the best model is LGBM with F1 score 0.041666666666666664 and Next Candlestick Pattern 1\n",
      "For GSDHO.IS, the best model is CatBoost with F1 score 0.041666666666666664 and Next Candlestick Pattern 1\n",
      "For EKGYO.IS, the best model is CatBoost with F1 score 0.04081632653061225 and Next Candlestick Pattern 1\n",
      "For TTRAK.IS, the best model is LGBM with F1 score 0.04054054054054054 and Next Candlestick Pattern 1\n",
      "For KOZAL.IS, the best model is CatBoost with F1 score 0.040268456375838924 and Next Candlestick Pattern 1\n",
      "For ENKAI.IS, the best model is CatBoost with F1 score 0.03361344537815126 and Next Candlestick Pattern 1\n",
      "For GUBRF.IS, the best model is LGBM with F1 score 0.029629629629629627 and Next Candlestick Pattern 1\n",
      "For TAVHL.IS, the best model is CatBoost with F1 score 0.028985507246376812 and Next Candlestick Pattern 1\n",
      "For KORDS.IS, the best model is CatBoost with F1 score 0.028169014084507043 and Next Candlestick Pattern 1\n",
      "For VESBE.IS, the best model is LGBM with F1 score 0.0202020202020202 and Next Candlestick Pattern 0\n",
      "For ISDMR.IS, the best model is LGBM with F1 score 0.019230769230769232 and Next Candlestick Pattern 1\n",
      "For BUCIM.IS, the best model is LGBM with F1 score 0.01785714285714286 and Next Candlestick Pattern 0\n",
      "For OTKAR.IS, the best model is LGBM with F1 score 0.017699115044247784 and Next Candlestick Pattern 0\n",
      "For ALBRK.IS, the best model is LGBM with F1 score 0.017543859649122806 and Next Candlestick Pattern 0\n",
      "For HALKB.IS, the best model is LGBM with F1 score 0.017241379310344827 and Next Candlestick Pattern 1\n",
      "For TRGYO.IS, the best model is LGBM with F1 score 0.01694915254237288 and Next Candlestick Pattern 1\n",
      "For SMRTG.IS, the best model is LGBM with F1 score 0.016666666666666666 and Next Candlestick Pattern 1\n",
      "For KCHOL.IS, the best model is CatBoost with F1 score 0.01652892561983471 and Next Candlestick Pattern 0\n",
      "For NTHOL.IS, the best model is LGBM with F1 score 0.016528925619834708 and Next Candlestick Pattern 1\n",
      "For VAKBN.IS, the best model is LGBM with F1 score 0.016129032258064516 and Next Candlestick Pattern 0\n",
      "For MAVI.IS, the best model is CatBoost with F1 score 0.016 and Next Candlestick Pattern 1\n",
      "For TOASO.IS, the best model is LGBM with F1 score 0.015873015873015876 and Next Candlestick Pattern 1\n",
      "For EREGL.IS, the best model is CatBoost with F1 score 0.015503875968992246 and Next Candlestick Pattern 1\n",
      "For PETKM.IS, the best model is CatBoost with F1 score 0.015151515151515152 and Next Candlestick Pattern 0\n",
      "For ALKIM.IS, the best model is LGBM with F1 score 0.014925373134328358 and Next Candlestick Pattern 1\n",
      "For AEFES.IS, the best model is CatBoost with F1 score 0.014598540145985401 and Next Candlestick Pattern 1\n",
      "For ARCLK.IS, the best model is LGBM with F1 score 0.0145985401459854 and Next Candlestick Pattern 1\n",
      "For ODAS.IS, the best model is CatBoost with F1 score 0.014598540145985398 and Next Candlestick Pattern 1\n",
      "For QUAGR.IS, the best model is CatBoost with F1 score 0.014184397163120565 and Next Candlestick Pattern 1\n",
      "For KOZAA.IS, the best model is LGBM with F1 score 0.013422818791946308 and Next Candlestick Pattern 1\n",
      "For ALGYO.IS, the best model is None with F1 score 0 and Next Candlestick Pattern 1\n",
      "For BERA.IS, the best model is None with F1 score 0 and Next Candlestick Pattern 0\n",
      "For BIMAS.IS, the best model is None with F1 score 0 and Next Candlestick Pattern 0\n",
      "For BRYAT.IS, the best model is None with F1 score 0 and Next Candlestick Pattern 0\n",
      "For DOHOL.IS, the best model is None with F1 score 0 and Next Candlestick Pattern 0\n",
      "For EGEEN.IS, the best model is None with F1 score 0 and Next Candlestick Pattern 0\n",
      "For ENJSA.IS, the best model is None with F1 score 0 and Next Candlestick Pattern 1\n",
      "For ERBOS.IS, the best model is None with F1 score 0 and Next Candlestick Pattern 0\n",
      "For FROTO.IS, the best model is None with F1 score 0 and Next Candlestick Pattern 0\n",
      "For SKBNK.IS, the best model is None with F1 score 0 and Next Candlestick Pattern 0\n",
      "For SOKM.IS, the best model is None with F1 score 0 and Next Candlestick Pattern 0\n",
      "For TURSG.IS, the best model is None with F1 score 0 and Next Candlestick Pattern 0\n",
      "\n",
      "Best Models Table:\n",
      "      Stock Best Model  Next Candlestick Pattern  Best F1 Score\n",
      "0  PGSUS.IS       LGBM                         1       0.333333\n",
      "1  NUGYO.IS   CatBoost                         1       0.256410\n",
      "2  KARSN.IS   CatBoost                         1       0.233129\n",
      "3   LOGO.IS   CatBoost                         1       0.190476\n",
      "4  KARTN.IS       LGBM                         1       0.167939\n",
      "5  GESAN.IS   CatBoost                         1       0.159420\n",
      "6  ISFIN.IS   CatBoost                         1       0.131387\n",
      "7  TSPOR.IS   CatBoost                         1       0.129032\n",
      "8  CEMTS.IS       LGBM                         1       0.125984\n",
      "9  PRKAB.IS   CatBoost                         1       0.124138\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_models(X_test, y_test, pipelines):\n",
    "    results = []\n",
    "    for model_name, pipeline in pipelines.items():\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"{model_name} Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(f\"{model_name} Precision: {precision}\")\n",
    "        print(f\"{model_name} Recall: {recall}\")\n",
    "        print(f\"{model_name} F1 Score: {f1}\")\n",
    "        print(f\"{model_name} Next Candle Prediction: {y_pred[-1]}\\n\")\n",
    "\n",
    "        # Save metrics for each model\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Download and preprocess data\n",
    "symbols = ['AEFES.IS', 'AGHOL.IS', 'AKBNK.IS', 'AKFGY.IS', 'AKSA.IS', 'AKSEN.IS',\n",
    "           'ALARK.IS', 'ALBRK.IS', 'ALGYO.IS', 'ALKIM.IS', 'ARCLK.IS', 'BAGFS.IS',\n",
    "           'BERA.IS', 'BIMAS.IS', 'BRYAT.IS', 'BUCIM.IS', 'CCOLA.IS', 'CEMTS.IS',\n",
    "           'CIMSA.IS', 'DEVA.IS', 'DOAS.IS', 'DOHOL.IS', 'ECILC.IS', 'EGEEN.IS',\n",
    "           'EKGYO.IS', 'ENJSA.IS', 'ENKAI.IS', 'ERBOS.IS', 'EREGL.IS', 'FROTO.IS',\n",
    "           'GARAN.IS',  'GESAN.IS', 'GLYHO.IS', 'GOZDE.IS', 'GSDHO.IS', 'GUBRF.IS',\n",
    "           'GWIND.IS', 'HALKB.IS', 'ISCTR.IS', 'ISDMR.IS', 'ISFIN.IS', 'ISGYO.IS',\n",
    "           'ISMEN.IS', 'JANTS.IS', 'KARSN.IS', 'KARTN.IS', 'KCHOL.IS', 'KONTR.IS',\n",
    "           'KORDS.IS', 'KOZAA.IS', 'KOZAL.IS', 'KRDMD.IS', 'LOGO.IS', 'MAVI.IS',\n",
    "           'MGROS.IS', 'NTHOL.IS', 'NUGYO.IS', 'ODAS.IS', 'OTKAR.IS', 'OYAKC.IS',\n",
    "           'PETKM.IS', 'PGSUS.IS', 'PRKAB.IS',  'QUAGR.IS', 'SAHOL.IS', 'SASA.IS',\n",
    "           'SKBNK.IS', 'SMRTG.IS', 'SNGYO.IS', 'SOKM.IS', 'TAVHL.IS', 'TCELL.IS',\n",
    "           'THYAO.IS', 'TKFEN.IS', 'TMSN.IS', 'TOASO.IS', 'TRGYO.IS', 'TSKB.IS',\n",
    "           'TSPOR.IS', 'TTKOM.IS', 'TTRAK.IS', 'TUKAS.IS', 'TUPRS.IS', 'TURSG.IS',\n",
    "           'ULKER.IS', 'VAKBN.IS', 'VESBE.IS', 'VESTL.IS', 'YATAS.IS', 'YKBNK.IS', 'YYLGD.IS']\n",
    "\n",
    "# Create an empty DataFrame to store features\n",
    "features_df = pd.DataFrame()\n",
    "\n",
    "# Loop through symbols and extract features\n",
    "for symbol in symbols:\n",
    "    # Download data\n",
    "    data = yf.download(symbol, start=\"2023-10-01\", end=\"2023-10-31\", interval=\"1h\")\n",
    "    ohlc, price_bins = load_data(data)\n",
    "\n",
    "    # Clean data\n",
    "    ohlc = ohlc.dropna()\n",
    "    price_bins = price_bins.dropna()\n",
    "\n",
    "    # Extract features\n",
    "    extracted_features = extract_features(data)\n",
    "    extracted_features['Symbol'] = symbol\n",
    "    features_df = features_df.append(extracted_features, ignore_index=True)\n",
    "\n",
    "# Drop 'Symbol' column for model training and evaluation\n",
    "X = features_df.drop(columns=['NextCandlestickPattern', 'Symbol'])\n",
    "y = features_df['NextCandlestickPattern']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# X_train ve y_train'i DataFrame'e çevirme\n",
    "X_train_df = pd.DataFrame(X_train, columns=X.columns)\n",
    "y_train_df = pd.DataFrame(y_train, columns=['NextCandlestickPattern'])\n",
    "X_valid_df = pd.DataFrame(X_valid, columns=X.columns)\n",
    "y_valid_df = pd.DataFrame(y_valid, columns=['NextCandlestickPattern'])\n",
    "\n",
    "#Changing nan and inf values in X_train and X_valid\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "X_valid.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_valid.fillna(X_valid.mean(), inplace=True)\n",
    "\n",
    "\n",
    "# Synchronize X_train and X_valid column names\n",
    "X_train = X_train[X_valid.columns]\n",
    "\n",
    "# Apply imputation to the entire dataset\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "columns_to_impute = ['EMA_5', 'EMA_13', 'EMA_50', 'SMA_5', 'SMA_13','SMA_50', 'MFI', 'MACD', 'RSI']\n",
    "\n",
    "# Fill missing values in the training dataset\n",
    "X_train[columns_to_impute] = imputer.fit_transform(X_train[columns_to_impute])\n",
    "y_train = np.where(y_train_df['NextCandlestickPattern'].shift(-1) > y_train_df['NextCandlestickPattern'], 1, 0)\n",
    "\n",
    "X_valid[columns_to_impute] = imputer.transform(X_valid[columns_to_impute])\n",
    "y_valid = np.where(y_valid_df['NextCandlestickPattern'].shift(-1) > y_valid_df['NextCandlestickPattern'], 1, 0)\n",
    "\n",
    "\n",
    "# Hyper-parameter optimization using Optuna\n",
    "\n",
    "# RandomForest\n",
    "def train_randomforest_optuna(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 30),\n",
    "        'min_samples_split': trial.suggest_float('min_samples_split', 0.1, 1.0),\n",
    "        'min_samples_leaf': trial.suggest_float('min_samples_leaf', 0.1, 0.5)\n",
    "\n",
    "    }\n",
    "\n",
    "    model = RandomForestClassifier(**params)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_valid)\n",
    "    f1 = f1_score(y_valid, preds)\n",
    "\n",
    "    return f1\n",
    "\n",
    "randomforest_study = optuna.create_study(direction='maximize')\n",
    "randomforest_study.optimize(train_randomforest_optuna, n_trials=100)\n",
    "randomforest_best_params = randomforest_study.best_params\n",
    "randomforest_model = RandomForestClassifier(**randomforest_best_params)\n",
    "randomforest_model.fit(X_train, y_train)\n",
    "\n",
    "# LightGBM\n",
    "def train_lightgbm_optuna(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 150),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.1, 1.0),\n",
    "        'early_stopping_rounds': 5,\n",
    "        'verbose': -1\n",
    "\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "\n",
    "    preds = model.predict(X_valid)\n",
    "    f1 = f1_score(y_valid, preds)\n",
    "\n",
    "    return f1\n",
    "\n",
    "\n",
    "lightgbm_study = optuna.create_study(direction='maximize')\n",
    "lightgbm_study.optimize(train_lightgbm_optuna, n_trials=100)\n",
    "lightgbm_best_params = lightgbm_study.best_params\n",
    "lightgbm_model = LGBMClassifier(**lightgbm_best_params)\n",
    "lightgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# CatBoost\n",
    "def train_catboost_optuna(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 800),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'early_stopping_rounds': 5,\n",
    "        'logging_level': 'Silent'\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "\n",
    "    preds = model.predict(X_valid)\n",
    "    f1 = f1_score(y_valid, preds)\n",
    "\n",
    "    return f1\n",
    "\n",
    "catboost_study = optuna.create_study(direction='maximize')\n",
    "catboost_study.optimize(train_catboost_optuna, n_trials=100)\n",
    "catboost_best_params = catboost_study.best_params\n",
    "catboost_model = CatBoostClassifier(**catboost_best_params)\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Train the models\n",
    "pipeline_rf = Pipeline(steps=[('model', randomforest_model)])\n",
    "pipeline_lgbm = Pipeline(steps=[('model', lightgbm_model)])\n",
    "pipeline_catboost = Pipeline(steps=[('model', catboost_model)])\n",
    "\n",
    "# Predictions on the test set for each model\n",
    "y_pred_rf = pipeline_rf.predict(X_valid)\n",
    "y_pred_lgbm = pipeline_lgbm.predict(X_valid)\n",
    "y_pred_catboost = pipeline_catboost.predict(X_valid)\n",
    "\n",
    "# Evaluate models\n",
    "pipelines = {\n",
    "    'RandomForest': pipeline_rf,\n",
    "    'LGBM': pipeline_lgbm,\n",
    "    'CatBoost': pipeline_catboost\n",
    "}\n",
    "\n",
    "evaluate_models(X_valid, y_valid, pipelines)\n",
    "\n",
    "# Find the best model for each stock based on F1 score\n",
    "best_models = []\n",
    "for symbol in symbols:\n",
    "    symbol_data = features_df[features_df['Symbol'] == symbol]\n",
    "    X_symbol = symbol_data.drop(columns=['NextCandlestickPattern', 'Symbol'])\n",
    "\n",
    "    X_symbol[columns_to_impute] = imputer.fit_transform(X_symbol[columns_to_impute])\n",
    "\n",
    "    # inf değerleri kontrol et ve düzelt\n",
    "    X_symbol.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X_symbol.fillna(X_symbol.mean(), inplace=True)\n",
    "\n",
    "    y_symbol = symbol_data['NextCandlestickPattern']\n",
    "\n",
    "    best_f1 = 0\n",
    "    best_model = None\n",
    "\n",
    "    for model_name, pipeline in pipelines.items():\n",
    "        y_pred_symbol = pipeline.predict(X_symbol)\n",
    "        f1_symbol = f1_score(y_symbol, y_pred_symbol)\n",
    "\n",
    "        if f1_symbol > best_f1:\n",
    "            best_f1 = f1_symbol\n",
    "            best_model = model_name\n",
    "\n",
    "    # Append the best model name and score to the results\n",
    "    best_models.append({\n",
    "        'Symbol': symbol,\n",
    "        'Best Model': best_model,\n",
    "        'Best F1 Score': best_f1,\n",
    "        'Next Candlestick Pattern': y_symbol.values[0]\n",
    "    })\n",
    "\n",
    "# Sort the best models by F1 score in descending order\n",
    "best_models.sort(key=lambda x: x['Best F1 Score'], reverse=True)\n",
    "\n",
    "# Print the results for each stock\n",
    "for result in best_models:\n",
    "    print(f\"For {result['Symbol']}, the best model is {result['Best Model']} with F1 score {result['Best F1 Score']} and Next Candlestick Pattern {result['Next Candlestick Pattern']}\")\n",
    "\n",
    "# Create a table for the best models and their performance\n",
    "best_models_table = [\n",
    "    [\"Stock\", \"Best Model\", \"Next Candlestick Pattern\", \"Best F1 Score\"]\n",
    "]\n",
    "\n",
    "# Append the top 10 best models to the table\n",
    "for result in best_models[:10]:\n",
    "    best_models_table.append([\n",
    "        result['Symbol'],\n",
    "        result['Best Model'],\n",
    "        result['Next Candlestick Pattern'],\n",
    "        result['Best F1 Score']\n",
    "    ])\n",
    "\n",
    "# Convert the table to a pandas DataFrame\n",
    "best_models_df = pd.DataFrame(best_models_table[1:], columns=best_models_table[0])\n",
    "\n",
    "# Print the best models table\n",
    "print(\"\\nBest Models Table:\")\n",
    "print(best_models_df)\n",
    "\n",
    "# Visualize the top 10 best models DataFrame\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "ax.table(cellText=best_models_df.values,\n",
    "         colLabels=best_models_df.columns,\n",
    "         cellLoc='center',\n",
    "         loc='center')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "AobQkNmRS7O4",
    "y9r4M3pcmDyz",
    "hHaTCLMjTEXX",
    "Dkm3XedUTH_H",
    "TTBCKoi3sp27"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
